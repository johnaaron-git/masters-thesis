This literature review's focus is on anomaly detection and explanation in dynamic graphs. The review is divided into four parts, one covering literature on fraud and anomaly detection in static and dynamic graphs respectively and the others focusing on literature related to explanation in static and dynamic graphs. This division is due to the fact that the original purpose of the research was to explore explainability in the context of anomaly detection in dynamic graphs. However, it was found that there is limited literature available on this topic, which led to the division of the literature review into three distinct parts. This literature review aims to provide a detailed analysis of the current research trends and gaps.
It is important to note that knowledge graphs aren't included in this paper. In fact, due to their different nature , knowledge graph explanability is already widely explored in static and dynamic context.

\subsection{GNN Fraud explanation in static graphs}
One key difference between anomaly detection and classification in dynamic graphs is the nature of the problem being solved. In anomaly detection, the goal is to identify rare or unexpected events that deviate from the norm, whereas in classification, the goal is to assign a label or category to each node or edge based on its properties. Anomaly detection is therefore a more complex problem, as it involves identifying patterns that are not easily discernible from the underlying data.

Another difference is the set of constraints that come with anomaly detection. Since anomalies are by definition rare or unexpected events, they may not be well-represented in the training data. This means that anomaly detection algorithms may need to be designed to work with limited or incomplete data, and to be robust to noisy or unreliable data. Because of these differences, classification models need to be adapted for anomaly detection.

Libraries like DIG and PyGOD libraries, which have gained popularity in recent years due to their ability to provide efficient and reliable anomaly detection algorithms. DIG, which stands for Dive into Graphs. Similarly, PyGOD, which stands for Python Graph-based Outlier Detection, is another library that provides graph-based approaches for anomaly detection. 

Anomaly detection and fraud detection are related but distinct problems. In fraud detection camouflage is considered as the norm. Camouflage is a technique used by fraudsters to hide their fraudulent activities. For example, in a financial transaction network, a fraudster may try to hide their fraudulent transactions by making them appear similar to legitimate transactions.

The cost of false positives and false negatives in anomaly detection and fraud detection can be significant. A false positive occurs when a normal data point is flagged as anomalous or fraudulent, while a false negative occurs when an anomalous or fraudulent data point is not flagged. False positives can lead to unnecessary investigations or actions, while false negatives can result in missed opportunities to detect and prevent fraud. The cost of false positives and false negatives will depend on the specific application and context. Having a cost aware detection model is key in Financial systems. However few are the papers that focuses on cost for the Bank. This is a possible future direction.



\begin{table}
\caption{GNN Fraud detection and explanation in static graphs}\label{tab1}
\begin{tabular}{|l|l|l|l|l|}
\hline
Paper &  Year & Technique & Explanability type & Learning\\
\hline
Rao et al.\cite{xfraud} &  2021 & xFraud & Perturbation & Supervised\\
Qin et al.\cite{NGS} &  2022 & NGS  & Perturbation& Supervised\\
Viloria et al.\cite{RAP} & 2021 & GNNExplainer & Perturbation& Supervised\\
 WU et al.\cite{DEDGAT}& 2023 & DEDGAT & Perturbation& Supervised\\
\hline
\end{tabular}
\end{table}

The success of perturbation in fraud detection and explanation is important to note. According to a study by GraphFrameX \cite{graphframex}, their systematic evaluation framework was tested on a production use case, which was to explain fraudulent transactions in the e-commerce scenario at eBay. The study only focused on explaining correct predictions and found that GNNexplainer was the most effective method, returning both sufficient and necessary explanations. Unlike other methods, GNNExplainer computes edge and node features importance independently when solving the optimization problem, which explains its superiority in this case. The study also revealed that perturbation-based methods outperformed structure-based and gradient-based methods in this particular production use case. 

It is dangerous to solely rely on supervised techniques for anomaly detection with GNNs (Graph Neural Networks) because these models are only as good as the data they are trained on. Supervised techniques require labeled data, which means data with a clear indication of what is anomalous and what is not. However, in many cases, anomalous data may not be present in the training data, making it difficult for the model to accurately identify anomalous data in the real world. Unsupervised fraud detection and explanation using GNN in static graph is very challenging but would yield interesting results.

Note these paper are fraud specific but other broader anomaly detection technique can also work for fraud detection.

\subsection{GNN Anomaly detection in dynamic graphs}

In addition to topological and feature information, temporal data is also present in dynamic graphs. This can be very informative but is chanllenging to use. To address this challenge, dynamic GNNs typically use temporal convolutions, recurrent neural networks (RNNs), or attention mechanisms to incorporate temporal information into the model. These techniques allow the model to capture the temporal dependencies between nodes and to predict future states of the graph.

Pytorch geometric temporal (PyGT) \cite{rozemberczki2021pytorch} is an open-source library built on top of PyTorch Geometric, which is a popular library for deep learning on graphs. PyGT extends the capabilities of PyTorch Geometric to temporal graphs by providing a set of modules that enable the handling of graph sequences, i.e., a series of graphs that evolve over time. These modules allow for the creation of neural network models that can learn temporal patterns in the graph sequences, enabling tasks such as node classification, link prediction, and graph classification.


\begin{table}
\caption{Anomaly detection in dynamic graphs}\label{tab1}
\begin{tabular}{|l|l|l|l|l|l|}
\hline
Paper &  Year & Technique & detection & code & Learning\\
\hline
Zheng et al.\cite{addGraph} & 2019 & addGraph & edge & yes & semi-supervised\\
Li et al.\cite{dynWatch} & 2022 & DynWatch  & edge & yes & supervised\\
Jiang et al.\cite{TSAD} & 2022 & TSAD & community & no & supervised\\
& & TADDY &  & & \\
 & & T2EG &  & & \\
 & & DyHGN &  & & \\
 & & StrGNN &  & & \\
 & & DynAD &  & & \\
 & & ... &  & & \\
 & &  &  & & \\
\hline
\end{tabular}
\end{table}

This is not a comprehensive list since there is too many papers on the topic. However survey on Anomaly detection in dynamic graphs with a clear structure would be of great help to the current literature. Some sureys like https://arxiv.org/pdf/2209.14930.pdf or https://www.sciencedirect.com/science/article/pii/S0166361521001056 did a partial work in the huge sorting problem that a global survey on GNN anomlay detection in dynamic graph would be.

Note these paper are anomaly specific but other broader classification technique like EvolveGCN\cite{egcn} can also work for anomaly detection in dynamic graphs.

\subsection{Explanation Survey's for static graphs}
Explanation in static graphs is already widely explored. The following 4 surveys provide a comprehensive overview of the state-of-the-art in explainability methods for static graphs, with a focus on GNNs. They propose taxonomies and frameworks for evaluating and comparing different methods, and highlight the open research questions in the field.

\begin{itemize}
    
    \item Trustworthy GNN: aspects, methods and trends\cite{trustworthy} elaborate six aspects of trust in GNN. Robustness, explainability, privacy, fairness, accountability, and environmental well-being.
    \item Explainability in GNN: A taxonomic survey \cite{expl_survey} provide a branching for post-hoc explainers. It finds 5 categories: Gradient, Perturbation, Decomposition, Surrogate and Generation.
    \item GraphFramEx: Towards systematic evaluation of explainability methods for GNN\cite{graphframex} propose a structured way of evaluation explainers for node classificatin problems. The paper propose a Characterization score (weighted harmonic mean of fid+ and Fid-) for explanation evaluation.
    \item An explainable AI library for benchmarking graph explainers\cite{explainable_AI} benchmarks explainers based on ground truth explanation.

\end{itemize}


\subsection{GNN Predicition and Explanation in dynamic graphs}
extra challenges expl in dyn graphs

no existing libraries nor surveys

TO DO: put second header on top of first header, oreder table differently (dy vs temporal)

\begin{table}
\caption{Explanation in dynamic graphs}\label{tab1}
\begin{tabular}{|l|l|l|l|l|l|l|l|l|}
\hline
Paper &  Year & Technique & Technique class & explanation & Black Box & Task & Graph & Application \\
\hline
 Ye et al.\cite{BrainNetX}& 2022 & BrainNetX & Gradient(SA) & Node & STpGCN & NC & Temporal & brain \\
 He et al.\cite{PGM}& 2022& TGNNExplainer & Surrogate(PGM) & Graph & TGNN &  NOP & Temporal & traffic\\
 Xie et al.\cite{DGExpl}& 2022 & DGExplainer & Decomposition(LRP) & features & GCN-GRU & NR & dynamic & traffic\\
 Limeros et al.\cite{XHGP}& 2022 & XHGP & Perturbation(counterfactual) & interaction & GAT-GRU & MP &Temporal & autonomous cars\\
 Fan et al.\cite{gcn-se}& 2022 & GCN-SE & Perturbation & snapshot & GCN-SE & NC & dynamic & bibliography\\
 Yao et al.\cite{}& 2020 &  \\
 Yang et al.\cite{FraudMemo}& 2019 & FraudMemory & \\
\hline
\end{tabular}
\end{table}
*NC= node classification, NOP= node output prediction, NR=node regression, motion prediction

Note very few explainer on their own for dynamic graph. Most are small adaptation of static explainer placed on a dynamic model.