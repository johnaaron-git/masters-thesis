
@article{ma_comprehensive_2021,
	title = {A Comprehensive Survey on Graph Anomaly Detection with Deep Learning},
	issn = {1558-2191},
	doi = {10.1109/TKDE.2021.3118815},
	abstract = {Over the last forty years, researches on anomalies have received intensified interests and the burst of information has attracted more attention on anomalies because of their significance in a wide range of disciplines. Anomaly detection, which aims to identify these rare observations, is among the most vital tasks and has shown its power in preventing detrimental events, such as financial fraud, network intrusion, and social spam, from happening. The detection task is typically solved by detecting outlying data in the features space and inherently overlooks the structural information. Graphs have been prevalently used to preserve structural information, and this raises the graph anomaly detection problem - identifying anomalous graph objects (nodes, edges, sub-graphs, and graphs). However, conventional anomaly detection techniques cannot well solve this problem because of the complexity of graph data. For the aptitudes of deep learning in breaking these limitations, graph anomaly detection with deep learning has received intensified studies recently. In this survey, we aim to provide a systematic and comprehensive review of the contemporary deep learning techniques for graph anomaly detection. We also highlight twelve extensive future research directions according to our survey results covering emerging problems introduced by graph data, anomaly detection and real applications.},
	pages = {1--1},
	journaltitle = {{IEEE} Transactions on Knowledge and Data Engineering},
	author = {Ma, Xiaoxiao and Wu, Jia and Xue, Shan and Yang, Jian and Zhou, Chuan and Sheng, Quan Z. and Xiong, Hui and Akoglu, Leman},
	date = {2021},
	note = {Conference Name: {IEEE} Transactions on Knowledge and Data Engineering},
	keywords = {Anomaly Detection, Anomaly detection, Deep Learning, Deep learning, Feature extraction, Graph Anomaly Detection, Graph Mining, Graph Neural Networks, Image edge detection, Object recognition, Social networking (online), Training},
}

@article{lindemann_survey_2021,
	title = {A survey on anomaly detection for technical systems using {LSTM} networks},
	volume = {131},
	issn = {0166-3615},
	url = {https://www.sciencedirect.com/science/article/pii/S0166361521001056},
	doi = {10.1016/j.compind.2021.103498},
	abstract = {Anomalies represent deviations from the intended system operation and can lead to decreased efficiency as well as partial or complete system failure. As the causes of anomalies are often unknown due to complex system dynamics, efficient anomaly detection is necessary. Conventional detection approaches rely on statistical and time-invariant methods that fail to address the complex and dynamic nature of anomalies. With advances in artificial intelligence and increasing importance for anomaly detection and prevention in various domains, artificial neural network approaches enable the detection of more complex anomaly types while considering temporal and contextual characteristics. In this article, a survey on state-of-the-art anomaly detection using deep neural and especially long short-term memory networks is conducted. The investigated approaches are evaluated based on the application scenario, data and anomaly types as well as further metrics. To highlight the potential of upcoming anomaly detection techniques, graph-based and transfer learning approaches are also included in the survey, enabling the analysis of heterogeneous data as well as compensating for its shortage and improving the handling of dynamic processes.},
	pages = {103498},
	journaltitle = {Computers in Industry},
	shortjournal = {Computers in Industry},
	author = {Lindemann, Benjamin and Maschler, Benjamin and Sahlab, Nada and Weyrich, Michael},
	urldate = {2023-05-09},
	date = {2021-10-01},
	langid = {english},
	keywords = {Anomaly detection, Artificial intelligence, Autoencoder, Context modeling, Long short-term memory, Transfer learning},
}

@article{kim_graph_2022,
	title = {Graph Anomaly Detection With Graph Neural Networks: Current Status and Challenges},
	volume = {10},
	issn = {2169-3536},
	doi = {10.1109/ACCESS.2022.3211306},
	shorttitle = {Graph Anomaly Detection With Graph Neural Networks},
	abstract = {Graphs are used widely to model complex systems, and detecting anomalies in a graph is an important task in the analysis of complex systems. Graph anomalies are patterns in a graph that do not conform to normal patterns expected of the attributes and/or structures of the graph. In recent years, graph neural networks ({GNNs}) have been studied extensively and have successfully performed difficult machine learning tasks in node classification, link prediction, and graph classification thanks to the highly expressive capability via message passing in effectively learning graph representations. To solve the graph anomaly detection problem, {GNN}-based methods leverage information about the graph attributes (or features) and/or structures to learn to score anomalies appropriately. In this survey, we review the recent advances made in detecting graph anomalies using {GNN} models. Specifically, we summarize {GNN}-based methods according to the graph type (i.e., static and dynamic), the anomaly type (i.e., node, edge, subgraph, and whole graph), and the network architecture (e.g., graph autoencoder, graph convolutional network). To the best of our knowledge, this survey is the first comprehensive review of graph anomaly detection methods based on {GNNs}.},
	pages = {111820--111829},
	journaltitle = {{IEEE} Access},
	author = {Kim, Hwan and Lee, Byung Suk and Shin, Won-Yong and Lim, Sungsu},
	date = {2022},
	note = {Conference Name: {IEEE} Access},
	keywords = {Anomaly detection, Decoding, Deep learning, Dynamic graph, Feature extraction, Graph neural networks, Image edge detection, Message passing, graph anomaly detection, graph neural network, node anomaly, static graph},
}

@misc{yao_interpretable_2021,
	title = {Interpretable Clustering on Dynamic Graphs with Recurrent Graph Neural Networks},
	url = {http://arxiv.org/abs/2012.08740},
	doi = {10.48550/arXiv.2012.08740},
	abstract = {We study the problem of clustering nodes in a dynamic graph, where the connections between nodes and nodes' cluster memberships may change over time, e.g., due to community migration. We first propose a dynamic stochastic block model that captures these changes, and a simple decay-based clustering algorithm that clusters nodes based on weighted connections between them, where the weight decreases at a fixed rate over time. This decay rate can then be interpreted as signifying the importance of including historical connection information in the clustering. However, the optimal decay rate may differ for clusters with different rates of turnover. We characterize the optimal decay rate for each cluster and propose a clustering method that achieves almost exact recovery of the true clusters. We then demonstrate the efficacy of our clustering algorithm with optimized decay rates on simulated graph data. Recurrent neural networks ({RNNs}), a popular algorithm for sequence learning, use a similar decay-based method, and we use this insight to propose two new {RNN}-{GCN} (graph convolutional network) architectures for semi-supervised graph clustering. We finally demonstrate that the proposed architectures perform well on real data compared to state-of-the-art graph clustering algorithms.},
	number = {{arXiv}:2012.08740},
	publisher = {{arXiv}},
	author = {Yao, Yuhang and Joe-Wong, Carlee},
	urldate = {2023-05-09},
	date = {2021-06-22},
	eprinttype = {arxiv},
	eprint = {2012.08740 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Social and Information Networks},
}

@misc{fan_gcn-se_2021,
	title = {{GCN}-{SE}: Attention as Explainability for Node Classification in Dynamic Graphs},
	url = {http://arxiv.org/abs/2110.05598},
	doi = {10.48550/arXiv.2110.05598},
	shorttitle = {{GCN}-{SE}},
	abstract = {Graph Convolutional Networks ({GCNs}) are a popular method from graph representation learning that have proved effective for tasks like node classification tasks. Although typical {GCN} models focus on classifying nodes within a static graph, several recent variants propose node classification in dynamic graphs whose topologies and node attributes change over time, e.g., social networks with dynamic relationships, or literature citation networks with changing co-authorships. These works, however, do not fully address the challenge of flexibly assigning different importance to snapshots of the graph at different times, which depending on the graph dynamics may have more or less predictive power on the labels. We address this challenge by proposing a new method, {GCN}-{SE}, that attaches a set of learnable attention weights to graph snapshots at different times, inspired by Squeeze and Excitation Net ({SE}-Net). We show that {GCN}-{SE} outperforms previously proposed node classification methods on a variety of graph datasets. To verify the effectiveness of the attention weight in determining the importance of different graph snapshots, we adapt perturbation-based methods from the field of explainable machine learning to graphical settings and evaluate the correlation between the attention weights learned by {GCN}-{SE} and the importance of different snapshots over time. These experiments demonstrate that {GCN}-{SE} can in fact identify different snapshots' predictive power for dynamic node classification.},
	number = {{arXiv}:2110.05598},
	publisher = {{arXiv}},
	author = {Fan, Yucai and Yao, Yuhang and Joe-Wong, Carlee},
	urldate = {2023-05-09},
	date = {2021-10-11},
	eprinttype = {arxiv},
	eprint = {2110.05598 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Social and Information Networks},
}

@book{yang_fraudmemory_2019,
	title = {{FraudMemory}: Explainable Memory-Enhanced Sequential Neural Networks for Financial Fraud Detection},
	isbn = {978-0-9981331-2-6},
	url = {http://hdl.handle.net/10125/59542},
	shorttitle = {{FraudMemory}},
	abstract = {The rapid development of electronic financial services brings significant convenience to our daily life. However, it also offers criminals the opportunity to exploit financial systems to do fraudulent transactions. Previous studies on fraud detection only deal with single type transactions and cannot adapt well to evolving environment in reality. In addition, their black box models pay less attention on the interpretability of fraud detection results. Here we propose a novel fraud detection algorithm called {FraudMemory}. It adopts state-of-art feature representation methods to better depict users and logs with multiple types in financial systems. Our model innovatively uses sequential model to capture the sequential patterns of each transaction and leverages memory networks to improve both the performance and interpretability. Also, with the incorporation of memory components, {FraudMemory} possesses high adaptability to the existence of concept drift. The empirical study proves that our model is a potential tool for financial fraud detection.},
	author = {Yang, Kunlin and Xu, Wei},
	urldate = {2023-05-09},
	date = {2019-01-08},
}

@misc{limeros_towards_2022,
	title = {Towards Explainable Motion Prediction using Heterogeneous Graph Representations},
	url = {http://arxiv.org/abs/2212.03806},
	doi = {10.48550/arXiv.2212.03806},
	abstract = {Motion prediction systems aim to capture the future behavior of traffic scenarios enabling autonomous vehicles to perform safe and efficient planning. The evolution of these scenarios is highly uncertain and depends on the interactions of agents with static and dynamic objects in the scene. {GNN}-based approaches have recently gained attention as they are well suited to naturally model these interactions. However, one of the main challenges that remains unexplored is how to address the complexity and opacity of these models in order to deal with the transparency requirements for autonomous driving systems, which includes aspects such as interpretability and explainability. In this work, we aim to improve the explainability of motion prediction systems by using different approaches. First, we propose a new Explainable Heterogeneous Graph-based Policy ({XHGP}) model based on an heterograph representation of the traffic scene and lane-graph traversals, which learns interaction behaviors using object-level and type-level attention. This learned attention provides information about the most important agents and interactions in the scene. Second, we explore this same idea with the explanations provided by {GNNExplainer}. Third, we apply counterfactual reasoning to provide explanations of selected individual scenarios by exploring the sensitivity of the trained model to changes made to the input data, i.e., masking some elements of the scene, modifying trajectories, and adding or removing dynamic agents. The explainability analysis provided in this paper is a first step towards more transparent and reliable motion prediction systems, important from the perspective of the user, developers and regulatory agencies. The code to reproduce this work is publicly available at https://github.com/sancarlim/Explainable-{MP}/tree/v1.1.},
	number = {{arXiv}:2212.03806},
	publisher = {{arXiv}},
	author = {Limeros, Sandra Carrasco and Majchrowska, Sylwia and Johnander, Joakim and Petersson, Christoffer and Llorca, David Fernández},
	urldate = {2023-05-09},
	date = {2022-12-07},
	eprinttype = {arxiv},
	eprint = {2212.03806 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Robotics},
}

@misc{xie_explaining_2022,
	title = {Explaining Dynamic Graph Neural Networks via Relevance Back-propagation},
	url = {http://arxiv.org/abs/2207.11175},
	doi = {10.48550/arXiv.2207.11175},
	abstract = {Graph Neural Networks ({GNNs}) have shown remarkable effectiveness in capturing abundant information in graph-structured data. However, the black-box nature of {GNNs} hinders users from understanding and trusting the models, thus leading to difficulties in their applications. While recent years witness the prosperity of the studies on explaining {GNNs}, most of them focus on static graphs, leaving the explanation of dynamic {GNNs} nearly unexplored. It is challenging to explain dynamic {GNNs}, due to their unique characteristic of time-varying graph structures. Directly using existing models designed for static graphs on dynamic graphs is not feasible because they ignore temporal dependencies among the snapshots. In this work, we propose {DGExplainer} to provide reliable explanation on dynamic {GNNs}. {DGExplainer} redistributes the output activation score of a dynamic {GNN} to the relevances of the neurons of its previous layer, which iterates until the relevance scores of the input neuron are obtained. We conduct quantitative and qualitative experiments on real-world datasets to demonstrate the effectiveness of the proposed framework for identifying important nodes for link prediction and node regression for dynamic {GNNs}.},
	number = {{arXiv}:2207.11175},
	publisher = {{arXiv}},
	author = {Xie, Jiaxuan and Liu, Yezi and Shen, Yanning},
	urldate = {2023-05-09},
	date = {2022-07-22},
	eprinttype = {arxiv},
	eprint = {2207.11175 [cs]},
	keywords = {Computer Science - Machine Learning},
}

@misc{he_explainer_2022,
	title = {An Explainer for Temporal Graph Neural Networks},
	url = {http://arxiv.org/abs/2209.00807},
	doi = {10.48550/arXiv.2209.00807},
	abstract = {Temporal graph neural networks ({TGNNs}) have been widely used for modeling time-evolving graph-related tasks due to their ability to capture both graph topology dependency and non-linear temporal dynamic. The explanation of {TGNNs} is of vital importance for a transparent and trustworthy model. However, the complex topology structure and temporal dependency make explaining {TGNN} models very challenging. In this paper, we propose a novel explainer framework for {TGNN} models. Given a time series on a graph to be explained, the framework can identify dominant explanations in the form of a probabilistic graphical model in a time period. Case studies on the transportation domain demonstrate that the proposed approach can discover dynamic dependency structures in a road network for a time period.},
	number = {{arXiv}:2209.00807},
	publisher = {{arXiv}},
	author = {He, Wenchong and Vu, Minh N. and Jiang, Zhe and Thai, My T.},
	urldate = {2023-05-09},
	date = {2022-09-02},
	eprinttype = {arxiv},
	eprint = {2209.00807 [cs]},
	keywords = {Computer Science - Machine Learning},
}

@article{ye_explainable_2023,
	title = {Explainable {fMRI}‐based brain decoding via spatial temporal‐pyramid graph convolutional network},
	volume = {44},
	issn = {1065-9471},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10089104/},
	doi = {10.1002/hbm.26255},
	abstract = {Brain decoding, aiming to identify the brain states using neural activity, is important for cognitive neuroscience and neural engineering. However, existing machine learning methods for {fMRI}‐based brain decoding either suffer from low classification performance or poor explainability. Here, we address this issue by proposing a biologically inspired architecture, Spatial Temporal‐pyramid Graph Convolutional Network ({STpGCN}), to capture the spatial–temporal graph representation of functional brain activities. By designing multi‐scale spatial–temporal pathways and bottom‐up pathways that mimic the information process and temporal integration in the brain, {STpGCN} is capable of explicitly utilizing the multi‐scale temporal dependency of brain activities via graph, thereby achieving high brain decoding performance. Additionally, we propose a sensitivity analysis method called {BrainNetX} to better explain the decoding results by automatically annotating task‐related brain regions from the brain‐network standpoint. We conduct extensive experiments on {fMRI} data under 23 cognitive tasks from Human Connectome Project ({HCP}) S1200. The results show that {STpGCN} significantly improves brain‐decoding performance compared to competing baseline models; {BrainNetX} successfully annotates task‐relevant brain regions. Post hoc analysis based on these regions further validates that the hierarchical structure in {STpGCN} significantly contributes to the explainability, robustness and generalization of the model. Our methods not only provide insights into information representation in the brain under multiple cognitive tasks but also indicate a bright future for {fMRI}‐based brain decoding., This work provides a biologically inspired graph deep learning‐based neural decoding method ({STpGCN}) and an model‐agnostic explainable tool ({BrainNetX}). These two methods opens a new window for the brain decoding using graph neural networks with spatial and multiple‐scale temporal dependencies. Besides the brain decoding, the proposed approaches hold promise for broad applications on neuroimages, such as brain disease detection.},
	pages = {2921--2935},
	number = {7},
	journaltitle = {Human Brain Mapping},
	shortjournal = {Hum Brain Mapp},
	author = {Ye, Ziyuan and Qu, Youzhi and Liang, Zhichao and Wang, Mo and Liu, Quanying},
	urldate = {2023-05-09},
	date = {2023-02-28},
	pmid = {36852610},
	pmcid = {PMC10089104},
}

@article{jiang_two-stage_2022,
	title = {Two-stage anomaly detection algorithm via dynamic community evolution in temporal graph},
	volume = {52},
	issn = {0924-669X, 1573-7497},
	url = {https://link.springer.com/10.1007/s10489-021-03109-4},
	doi = {10.1007/s10489-021-03109-4},
	abstract = {Detecting anomalies from a massive amount of user behavioral data is often liken to finding a needle in a haystack. While tremendous efforts have been devoted to anomaly detection from temporal graphs, existing studies rarely consider community evolution and evolutionary paths simultaneously, and analyze those characteristics for the purpose of anomaly detection. Therefore, we propose a two-stage anomaly detection ({TSAD}) framework to detect anomalies. In this study, we suggest detecting the community evolution events from a sequence of snapshot graphs by constructing an evolution bipartite graph and designing community similarity scores. We then propose a novel anomaly detection method combining community evolution-based anomaly detection and evolutionary path-based anomaly detection. An anomalous score is designed to detect anomalous community evolution events by extracting the characteristics of evolution communities in the community evolution-based anomaly detection method. Moreover, to reduce the false alarm rate, we propose evolutionary path-based anomaly detection to further detect the abnormality of the identified normal evolutionary paths by extracting the characteristics of the identified anomalous evolutionary paths based on community evolution-based anomaly detection. We conduct extensive experiments on real-world datasets and demonstrate that {TSAD} consistently outperforms competitive baseline methods in anomaly detection.},
	pages = {12222--12240},
	number = {11},
	journaltitle = {Applied Intelligence},
	shortjournal = {Appl Intell},
	author = {Jiang, Yan and Liu, Guannan},
	urldate = {2023-05-09},
	date = {2022-09},
	langid = {english},
}

@misc{lundberg_unified_2017,
	title = {A Unified Approach to Interpreting Model Predictions},
	url = {http://arxiv.org/abs/1705.07874},
	doi = {10.48550/arXiv.1705.07874},
	abstract = {Understanding why a model makes a certain prediction can be as crucial as the prediction's accuracy in many applications. However, the highest accuracy for large modern datasets is often achieved by complex models that even experts struggle to interpret, such as ensemble or deep learning models, creating a tension between accuracy and interpretability. In response, various methods have recently been proposed to help users interpret the predictions of complex models, but it is often unclear how these methods are related and when one method is preferable over another. To address this problem, we present a unified framework for interpreting predictions, {SHAP} ({SHapley} Additive {exPlanations}). {SHAP} assigns each feature an importance value for a particular prediction. Its novel components include: (1) the identification of a new class of additive feature importance measures, and (2) theoretical results showing there is a unique solution in this class with a set of desirable properties. The new class unifies six existing methods, notable because several recent methods in the class lack the proposed desirable properties. Based on insights from this unification, we present new methods that show improved computational performance and/or better consistency with human intuition than previous approaches.},
	number = {{arXiv}:1705.07874},
	publisher = {{arXiv}},
	author = {Lundberg, Scott and Lee, Su-In},
	urldate = {2023-05-09},
	date = {2017-11-24},
	eprinttype = {arxiv},
	eprint = {1705.07874 [cs, stat]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{yuan_explainability_2023,
	title = {Explainability in Graph Neural Networks: A Taxonomic Survey},
	volume = {45},
	issn = {1939-3539},
	doi = {10.1109/TPAMI.2022.3204236},
	shorttitle = {Explainability in Graph Neural Networks},
	abstract = {Deep learning methods are achieving ever-increasing performance on many artificial intelligence tasks. A major limitation of deep models is that they are not amenable to interpretability. This limitation can be circumvented by developing post hoc techniques to explain predictions, giving rise to the area of explainability. Recently, explainability of deep models on images and texts has achieved significant progress. In the area of graph data, graph neural networks ({GNNs}) and their explainability are experiencing rapid developments. However, there is neither a unified treatment of {GNN} explainability methods, nor a standard benchmark and testbed for evaluations. In this survey, we provide a unified and taxonomic view of current {GNN} explainability methods. Our unified and taxonomic treatments of this subject shed lights on the commonalities and differences of existing methods and set the stage for further methodological developments. To facilitate evaluations, we provide a testbed for {GNN} explainability, including datasets, common algorithms and evaluation metrics. Furthermore, we conduct comprehensive experiments to compare and analyze the performance of many techniques. Altogether, this work provides a unified methodological treatment of {GNN} explainability and a standardized testbed for evaluations.},
	pages = {5782--5799},
	number = {5},
	journaltitle = {{IEEE} Transactions on Pattern Analysis and Machine Intelligence},
	author = {Yuan, Hao and Yu, Haiyang and Gui, Shurui and Ji, Shuiwang},
	date = {2023-05},
	note = {Conference Name: {IEEE} Transactions on Pattern Analysis and Machine Intelligence},
	keywords = {Biological system modeling, Data models, Graph analysis, Graph neural networks, Predictive models, Systematics, Task analysis, Taxonomy, evaluation, explainability, graph neural networks, interpretability, survey, taxonomy},
}

@article{li_dynamic_2022,
	title = {Dynamic Graph-Based Anomaly Detection in the Electrical Grid},
	volume = {37},
	issn = {1558-0679},
	doi = {10.1109/TPWRS.2021.3132852},
	abstract = {Given sensor readings over time from a power grid, how can we accurately detect when an anomaly occurs? A key part of achieving this goal is to use the network of power grid sensors to quickly detect, in real-time, when any unusual events, whether natural faults or malicious, occur on the power grid. Existing bad-data detectors in the industry lack the sophistication to robustly detect broad types of anomalies, especially those due to emerging cyber-attacks, since they operate on a single measurement snapshot of the grid at a time. New {ML} methods are more widely applicable, but generally do not consider the impact of topology change on sensor measurements and thus cannot accommodate regular topology adjustments in historical data. Hence, we propose {DynWatch}, a domain knowledge based and topology-aware algorithm for anomaly detection using sensors placed on a dynamic grid. Our approach is accurate, outperforming existing approaches by 20\% or more (F-measure) in experiments; and fast, averaging less than 1.7 ms per time tick per sensor on a 60K+ branch case using a laptop computer, and scaling linearly with the size of the graph.},
	pages = {3408--3422},
	number = {5},
	journaltitle = {{IEEE} Transactions on Power Systems},
	author = {Li, Shimiao and Pandey, Amritanshu and Hooi, Bryan and Faloutsos, Christos and Pileggi, Larry},
	date = {2022-09},
	note = {Conference Name: {IEEE} Transactions on Power Systems},
	keywords = {Algorithms, Anomalies, Anomaly detection, Computer security, Electric power grids, Fault detection, {LODF}, Laptop computers, Network topology, Power grids, Power measurement, Power system dynamics, Sensors, Time series analysis, Topology, dynamic grid, graph distance, power system modeling},
}

@misc{acevedo-viloria_relational_2021,
	title = {Relational Graph Neural Networks for Fraud Detection in a Super-App environment},
	url = {http://arxiv.org/abs/2107.13673},
	doi = {10.48550/arXiv.2107.13673},
	abstract = {Large digital platforms create environments where different types of user interactions are captured, these relationships offer a novel source of information for fraud detection problems. In this paper we propose a framework of relational graph convolutional networks methods for fraudulent behaviour prevention in the financial services of a Super-App. To this end, we apply the framework on different heterogeneous graphs of users, devices, and credit cards; and finally use an interpretability algorithm for graph neural networks to determine the most important relations to the classification task of the users. Our results show that there is an added value when considering models that take advantage of the alternative data of the Super-App and the interactions found in their high connectivity, further proofing how they can leverage that into better decisions and fraud detection strategies.},
	number = {{arXiv}:2107.13673},
	publisher = {{arXiv}},
	author = {Acevedo-Viloria, Jaime D. and Roa, Luisa and Adeshina, Soji and Olazo, Cesar Charalla and Rodríguez-Rey, Andrés and Ramos, Jose Alberto and Correa-Bahnsen, Alejandro},
	urldate = {2023-05-09},
	date = {2021-07-30},
	eprinttype = {arxiv},
	eprint = {2107.13673 [cs, q-fin]},
	keywords = {Computer Science - Machine Learning, Quantitative Finance - General Finance},
}

@inproceedings{qin_explainable_2022,
	location = {New York, {NY}, {USA}},
	title = {Explainable Graph-based Fraud Detection via Neural Meta-graph Search},
	isbn = {978-1-4503-9236-5},
	url = {https://dl.acm.org/doi/10.1145/3511808.3557598},
	doi = {10.1145/3511808.3557598},
	series = {{CIKM} '22},
	abstract = {Though graph neural networks ({GNNs})-based fraud detectors have received remarkable success in identifying fraudulent activities, few of them pay equal attention to models' performance and explainability. In this paper, we attempt to achieve high performance for graph-based fraud detection while considering model explainability. We propose {NGS} (Neural meta-Graph Search), in which the message passing process of a {GNN} is formalized as a meta-graph, and a differentiable neural architecture search is devised to determine the optimized message passing graph structure. We further enhance the model by aggregating multiple searched meta-graphs to make the final prediction. Experimental results on two real-world datasets demonstrate that {NGS} outperforms state-of-the-art baselines. In addition, the searched meta-graphs concisely describe the information used for prediction and produce reasonable explanations.},
	pages = {4414--4418},
	booktitle = {Proceedings of the 31st {ACM} International Conference on Information \& Knowledge Management},
	publisher = {Association for Computing Machinery},
	author = {Qin, Zidi and Liu, Yang and He, Qing and Ao, Xiang},
	urldate = {2023-05-09},
	date = {2022-10-17},
	keywords = {fraud detection, graph neural network, neural architecture search},
}

@misc{wu_dedgat_2023,
	title = {{DEDGAT}: Dual Embedding of Directed Graph Attention Networks for Detecting Financial Risk},
	url = {http://arxiv.org/abs/2303.03933},
	doi = {10.48550/arXiv.2303.03933},
	shorttitle = {{DEDGAT}},
	abstract = {Graph representation plays an important role in the field of financial risk control, where the relationship among users can be constructed in a graph manner. In practical scenarios, the relationships between nodes in risk control tasks are bidirectional, e.g., merchants having both revenue and expense behaviors. Graph neural networks designed for undirected graphs usually aggregate discriminative node or edge representations with an attention strategy, but cannot fully exploit the out-degree information when used for the tasks built on directed graph, which leads to the problem of a directional bias. To tackle this problem, we propose a Directed Graph {ATtention} network called {DGAT}, which explicitly takes out-degree into attention calculation. In addition to having directional requirements, the same node might have different representations of its input and output, and thus we further propose a dual embedding of {DGAT}, referred to as {DEDGAT}. Specifically, {DEDGAT} assigns in-degree and out-degree representations to each node and uses these two embeddings to calculate the attention weights of in-degree and out-degree nodes, respectively. Experiments performed on the benchmark datasets show that {DGAT} and {DEDGAT} obtain better classification performance compared to undirected {GAT}. Also,the visualization results demonstrate that our methods can fully use both in-degree and out-degree information.},
	number = {{arXiv}:2303.03933},
	publisher = {{arXiv}},
	author = {Wu, Jiafu and Yao, Mufeng and Wu, Dong and Chi, Mingmin and Wang, Baokun and Wu, Ruofan and Fu, Xin and Meng, Changhua and Wang, Weiqiang},
	urldate = {2023-05-09},
	date = {2023-03-06},
	eprinttype = {arxiv},
	eprint = {2303.03933 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Distributed, Parallel, and Cluster Computing, Computer Science - Machine Learning},
}

@article{rao_xfraud_2021,
	title = {{xFraud}: explainable fraud transaction detection},
	volume = {15},
	issn = {2150-8097},
	url = {https://dl.acm.org/doi/10.14778/3494124.3494128},
	doi = {10.14778/3494124.3494128},
	shorttitle = {{xFraud}},
	abstract = {At online retail platforms, it is crucial to actively detect the risks of transactions to improve customer experience and minimize financial loss. In this work, we propose {xFraud}, an explainable fraud transaction prediction framework which is mainly composed of a detector and an explainer. The {xFraud} detector can effectively and efficiently predict the legitimacy of incoming transactions. Specifically, it utilizes a heterogeneous graph neural network to learn expressive representations from the informative heterogeneously typed entities in the transaction logs. The explainer in {xFraud} can generate meaningful and human-understandable explanations from graphs to facilitate further processes in the business unit. In our experiments with {xFraud} on real transaction networks with up to 1.1 billion nodes and 3.7 billion edges, {xFraud} is able to outperform various baseline models in many evaluation metrics while remaining scalable in distributed settings. In addition, we show that {xFraud} explainer can generate reasonable explanations to significantly assist the business analysis via both quantitative and qualitative evaluations.},
	pages = {427--436},
	number = {3},
	journaltitle = {Proceedings of the {VLDB} Endowment},
	shortjournal = {Proc. {VLDB} Endow.},
	author = {Rao, Susie Xi and Zhang, Shuai and Han, Zhichao and Zhang, Zitao and Min, Wei and Chen, Zhiyao and Shan, Yinan and Zhao, Yang and Zhang, Ce},
	urldate = {2023-05-09},
	date = {2021-11-01},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Computer Science - Social and Information Networks, I.2.6},
}

@misc{li_explainability_2022,
	title = {Explainability in Graph Neural Networks: An Experimental Survey},
	url = {http://arxiv.org/abs/2203.09258},
	doi = {10.48550/arXiv.2203.09258},
	shorttitle = {Explainability in Graph Neural Networks},
	abstract = {Graph neural networks ({GNNs}) have been extensively developed for graph representation learning in various application domains. However, similar to all other neural networks models, {GNNs} suffer from the black-box problem as people cannot understand the mechanism underlying them. To solve this problem, several {GNN} explainability methods have been proposed to explain the decisions made by {GNNs}. In this survey, we give an overview of the state-of-the-art {GNN} explainability methods and how they are evaluated. Furthermore, we propose a new evaluation metric and conduct thorough experiments to compare {GNN} explainability methods on real world datasets. We also suggest future directions for {GNN} explainability.},
	number = {{arXiv}:2203.09258},
	publisher = {{arXiv}},
	author = {Li, Peibo and Yang, Yixing and Pagnucco, Maurice and Song, Yang},
	urldate = {2023-05-09},
	date = {2022-03-17},
	eprinttype = {arxiv},
	eprint = {2203.09258 [cs]},
	keywords = {A.1, Computer Science - Artificial Intelligence, Computer Science - Machine Learning, I.2.0},
}

@misc{dai_comprehensive_2022,
	title = {A Comprehensive Survey on Trustworthy Graph Neural Networks: Privacy, Robustness, Fairness, and Explainability},
	url = {http://arxiv.org/abs/2204.08570},
	doi = {10.48550/arXiv.2204.08570},
	shorttitle = {A Comprehensive Survey on Trustworthy Graph Neural Networks},
	abstract = {Graph Neural Networks ({GNNs}) have made rapid developments in the recent years. Due to their great ability in modeling graph-structured data, {GNNs} are vastly used in various applications, including high-stakes scenarios such as financial analysis, traffic predictions, and drug discovery. Despite their great potential in benefiting humans in the real world, recent study shows that {GNNs} can leak private information, are vulnerable to adversarial attacks, can inherit and magnify societal bias from training data and lack interpretability, which have risk of causing unintentional harm to the users and society. For example, existing works demonstrate that attackers can fool the {GNNs} to give the outcome they desire with unnoticeable perturbation on training graph. {GNNs} trained on social networks may embed the discrimination in their decision process, strengthening the undesirable societal bias. Consequently, trustworthy {GNNs} in various aspects are emerging to prevent the harm from {GNN} models and increase the users' trust in {GNNs}. In this paper, we give a comprehensive survey of {GNNs} in the computational aspects of privacy, robustness, fairness, and explainability. For each aspect, we give the taxonomy of the related methods and formulate the general frameworks for the multiple categories of trustworthy {GNNs}. We also discuss the future research directions of each aspect and connections between these aspects to help achieve trustworthiness.},
	number = {{arXiv}:2204.08570},
	publisher = {{arXiv}},
	author = {Dai, Enyan and Zhao, Tianxiang and Zhu, Huaisheng and Xu, Junjie and Guo, Zhimeng and Liu, Hui and Tang, Jiliang and Wang, Suhang},
	urldate = {2023-05-09},
	date = {2022-04-18},
	eprinttype = {arxiv},
	eprint = {2204.08570 [cs]},
	keywords = {Computer Science - Cryptography and Security, Computer Science - Machine Learning},
}

@misc{amara_graphframex_2022,
	title = {{GraphFramEx}: Towards Systematic Evaluation of Explainability Methods for Graph Neural Networks},
	url = {http://arxiv.org/abs/2206.09677},
	doi = {10.48550/arXiv.2206.09677},
	shorttitle = {{GraphFramEx}},
	abstract = {As one of the most popular machine learning models today, graph neural networks ({GNNs}) have attracted intense interest recently, and so does their explainability. Users are increasingly interested in a better understanding of {GNN} models and their outcomes. Unfortunately, today's evaluation frameworks for {GNN} explainability often rely on few inadequate synthetic datasets, leading to conclusions of limited scope due to a lack of complexity in the problem instances. As {GNN} models are deployed to more mission-critical applications, we are in dire need for a common evaluation protocol of explainability methods of {GNNs}. In this paper, we propose, to our best knowledge, the first systematic evaluation framework for {GNN} explainability, considering explainability on three different "user needs". We propose a unique metric that combines the fidelity measures and classifies explanations based on their quality of being sufficient or necessary. We scope ourselves to node classification tasks and compare the most representative techniques in the field of input-level explainability for {GNNs}. For the inadequate but widely used synthetic benchmarks, surprisingly shallow techniques such as personalized {PageRank} have the best performance for a minimum computation time. But when the graph structure is more complex and nodes have meaningful features, gradient-based methods are the best according to our evaluation criteria. However, none dominates the others on all evaluation dimensions and there is always a trade-off. We further apply our evaluation protocol in a case study for frauds explanation on {eBay} transaction graphs to reflect the production environment.},
	number = {{arXiv}:2206.09677},
	publisher = {{arXiv}},
	author = {Amara, Kenza and Ying, Rex and Zhang, Zitao and Han, Zhihao and Shan, Yinan and Brandes, Ulrik and Schemm, Sebastian and Zhang, Ce},
	urldate = {2023-05-09},
	date = {2022-10-11},
	eprinttype = {arxiv},
	eprint = {2206.09677 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
}

@misc{agarwal_explainable_nodate,
	title = {An Explainable {AI} Library for Benchmarking Graph Explainers},
	url = {https://graph-learning-benchmarks.github.io/assets/papers/glb2022/An_Explainable_AI_Library_for_Benchmarking_Graph_Explainers.pdf},
	abstract = {With Graph Neural Network ({GNN}) explainability methods increasingly used to understand {GNN} predictions in critical real-world applications, it is essential to reliably evaluate the correctness of generated explanations. However, assessing the quality of {GNN} explanations is challenging as existing evaluation strategies depend on specific datasets with no or unreliable ground-truth explanations and {GNN} models. Here, we introduce G-{XAI} Bench, an open-source graph explainability library providing a systematic framework in {PyTorch} and {PyTorch} Geometric to compare and evaluate the reliability of {GNN} explanations. G-{XAI} Bench provides comprehensive programmatic functionality in the form of data processing functions, {GNN} model implementations, collections of synthetic and real-world graph datasets, {GNN} explainers, and performance metrics to benchmark any {GNN} explainability method. We introduced G-{XAI} Bench to support the development of novel methods with a strong bent towards developing the foundations of which {GNN} explainers are most suitable for specific applications and why.},
	publisher = {Workshop on Graph Learning Benchmarks  ({GLB} 2022)},
	author = {Agarwal, Chirag and Queen, Owen and Lakkaraju, Himabindu and Zitnik, Marinka},
}

@misc{pareja_evolvegcn_2019,
	title = {{EvolveGCN}: Evolving Graph Convolutional Networks for Dynamic Graphs},
	url = {http://arxiv.org/abs/1902.10191},
	doi = {10.48550/arXiv.1902.10191},
	shorttitle = {{EvolveGCN}},
	abstract = {Graph representation learning resurges as a trending research subject owing to the widespread use of deep learning for Euclidean data, which inspire various creative designs of neural networks in the non-Euclidean domain, particularly graphs. With the success of these graph neural networks ({GNN}) in the static setting, we approach further practical scenarios where the graph dynamically evolves. Existing approaches typically resort to node embeddings and use a recurrent neural network ({RNN}, broadly speaking) to regulate the embeddings and learn the temporal dynamics. These methods require the knowledge of a node in the full time span (including both training and testing) and are less applicable to the frequent change of the node set. In some extreme scenarios, the node sets at different time steps may completely differ. To resolve this challenge, we propose {EvolveGCN}, which adapts the graph convolutional network ({GCN}) model along the temporal dimension without resorting to node embeddings. The proposed approach captures the dynamism of the graph sequence through using an {RNN} to evolve the {GCN} parameters. Two architectures are considered for the parameter evolution. We evaluate the proposed approach on tasks including link prediction, edge classification, and node classification. The experimental results indicate a generally higher performance of {EvolveGCN} compared with related approaches. The code is available at {\textbackslash}url\{https://github.com/{IBM}/{EvolveGCN}\}.},
	number = {{arXiv}:1902.10191},
	publisher = {{arXiv}},
	author = {Pareja, Aldo and Domeniconi, Giacomo and Chen, Jie and Ma, Tengfei and Suzumura, Toyotaro and Kanezashi, Hiroki and Kaler, Tim and Schardl, Tao B. and Leiserson, Charles E.},
	urldate = {2023-05-09},
	date = {2019-11-18},
	eprinttype = {arxiv},
	eprint = {1902.10191 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Computer Science - Social and Information Networks, Statistics - Machine Learning},
}

@inproceedings{rozemberczki_pytorch_2021,
	location = {New York, {NY}, {USA}},
	title = {{PyTorch} Geometric Temporal: Spatiotemporal Signal Processing with Neural Machine Learning Models},
	isbn = {978-1-4503-8446-9},
	url = {https://dl.acm.org/doi/10.1145/3459637.3482014},
	doi = {10.1145/3459637.3482014},
	series = {{CIKM} '21},
	shorttitle = {{PyTorch} Geometric Temporal},
	abstract = {We present {PyTorch} Geometric Temporal, a deep learning framework combining state-of-the-art machine learning algorithms for neural spatiotemporal signal processing. The main goal of the library is to make temporal geometric deep learning available for researchers and machine learning practitioners in a unified easy-to-use framework. {PyTorch} Geometric Temporal was created with foundations on existing libraries in the {PyTorch} eco-system, streamlined neural network layer definitions, temporal snapshot generators for batching, and integrated benchmark datasets. These features are illustrated with a tutorial-like case study. Experiments demonstrate the predictive performance of the models implemented in the library on real-world problems such as epidemiological forecasting, ride-hail demand prediction, and web traffic management. Our sensitivity analysis of runtime shows that the framework can potentially operate on web-scale datasets with rich temporal features and spatial structure.},
	pages = {4564--4573},
	booktitle = {Proceedings of the 30th {ACM} International Conference on Information \& Knowledge Management},
	publisher = {Association for Computing Machinery},
	author = {Rozemberczki, Benedek and Scherer, Paul and He, Yixuan and Panagopoulos, George and Riedel, Alexander and Astefanoaei, Maria and Kiss, Oliver and Beres, Ferenc and López, Guzmán and Collignon, Nicolas and Sarkar, Rik},
	urldate = {2023-05-09},
	date = {2021-10-30},
	keywords = {deep learning, graph neural networks, machine learning, time series data},
}

@misc{rao_modelling_2022,
	title = {Modelling graph dynamics in fraud detection with "Attention"},
	url = {http://arxiv.org/abs/2204.10614},
	abstract = {At online retail platforms, detecting fraudulent accounts and transactions is crucial to improve customer experience, minimize loss, and avoid unauthorized transactions. Despite the variety of different models for deep learning on graphs, few approaches have been proposed for dealing with graphs that are both heterogeneous and dynamic. In this paper, we propose {DyHGN} (Dynamic Heterogeneous Graph Neural Network) and its variants to capture both temporal and heterogeneous information. We first construct dynamic heterogeneous graphs from registration and transaction data from {eBay}. Then, we build models with diachronic entity embedding and heterogeneous graph transformer. We also use model explainability techniques to understand the behaviors of {DyHGN}-* models. Our findings reveal that modelling graph dynamics with heterogeneous inputs need to be conducted with “attention" depending on the data structure, distribution, and computation cost.},
	number = {{arXiv}:2204.10614},
	publisher = {{arXiv}},
	author = {Rao, Susie Xi and Lanfranchi, Clémence and Zhang, Shuai and Han, Zhichao and Zhang, Zitao and Min, Wei and Cheng, Mo and Shan, Yinan and Zhao, Yang and Zhang, Ce},
	urldate = {2022-11-27},
	date = {2022-04-22},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {2204.10614 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Computer Science - Social and Information Networks},
}

@inproceedings{zheng_addgraph_2019,
	location = {Macao, China},
	title = {{AddGraph}: Anomaly Detection in Dynamic Graph Using Attention-based Temporal {GCN}},
	isbn = {978-0-9992411-4-1},
	url = {https://www.ijcai.org/proceedings/2019/614},
	doi = {10.24963/ijcai.2019/614},
	shorttitle = {{AddGraph}},
	abstract = {Anomaly detection in dynamic graphs becomes very critical in many different application scenarios, e.g., recommender systems, while it also raises huge challenges due to the high ﬂexible nature of anomaly and lack of sufﬁcient labelled data. It is better to learn the anomaly patterns by considering all possible hints including the structural, content and temporal features, rather than utilizing heuristic rules over the partial features. In this paper, we propose {AddGraph}, a general end-to-end anomalous edge detection framework using an extended temporal {GCN} (Graph Convolutional Network) with an attention model, which can capture both long-term patterns and the short-term patterns in dynamic graphs. In order to cope with insufﬁcient explicit labelled data, we employ a selective negative sampling and margin loss in training of {AddGraph} in a semi-supervised fashion. We conduct extensive experiments on real-world datasets, and illustrate that {AddGraph} can outperform the state-of-the-art competitors in anomaly detection signiﬁcantly.},
	eventtitle = {Twenty-Eighth International Joint Conference on Artificial Intelligence \{{IJCAI}-19\}},
	pages = {4419--4425},
	booktitle = {Proceedings of the Twenty-Eighth International Joint Conference on Artificial Intelligence},
	publisher = {International Joint Conferences on Artificial Intelligence Organization},
	author = {Zheng, Li and Li, Zhenpeng and Li, Jian and Li, Zhao and Gao, Jun},
	urldate = {2022-11-30},
	date = {2019-08},
	langid = {english},
}

@misc{lv_are_2021,
	title = {Are we really making much progress? Revisiting, benchmarking, and refining heterogeneous graph neural networks},
	url = {http://arxiv.org/abs/2112.14936},
	shorttitle = {Are we really making much progress?},
	abstract = {Heterogeneous graph neural networks ({HGNNs}) have been blossoming in recent years, but the unique data processing and evaluation setups used by each work obstruct a full understanding of their advancements. In this work, we present a systematical reproduction of 12 recent {HGNNs} by using their official codes, datasets, settings, and hyperparameters, revealing surprising findings about the progress of {HGNNs}. We find that the simple homogeneous {GNNs}, e.g., {GCN} and {GAT}, are largely underestimated due to improper settings. {GAT} with proper inputs can generally match or outperform all existing {HGNNs} across various scenarios. To facilitate robust and reproducible {HGNN} research, we construct the Heterogeneous Graph Benchmark ({HGB})1, consisting of 11 diverse datasets with three tasks. {HGB} standardizes the process of heterogeneous graph data splits, feature processing, and performance evaluation. Finally, we introduce a simple but very strong baseline Simple-{HGN}—which significantly outperforms all previous models on {HGB}—to accelerate the advancement of {HGNNs} in the future.},
	number = {{arXiv}:2112.14936},
	publisher = {{arXiv}},
	author = {Lv, Qingsong and Ding, Ming and Liu, Qiang and Chen, Yuxiang and Feng, Wenzheng and He, Siming and Zhou, Chang and Jiang, Jianguo and Dong, Yuxiao and Tang, Jie},
	urldate = {2023-05-02},
	date = {2021-12-30},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {2112.14936 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Social and Information Networks},
}

@misc{cai_structural_2020,
	title = {Structural Temporal Graph Neural Networks for Anomaly Detection in Dynamic Graphs},
	url = {http://arxiv.org/abs/2005.07427},
	abstract = {Detecting anomalies in dynamic graphs is a vital task, with numerous practical applications in areas such as security, ﬁnance, and social media. Previous network embedding based methods have been mostly focusing on learning good node representations, whereas largely ignoring the subgraph structural changes related to the target nodes in dynamic graphs. In this paper, we propose {StrGNN}, an end-to-end structural temporal Graph Neural Network model for detecting anomalous edges in dynamic graphs. In particular, we ﬁrst extract the hhop enclosing subgraph centered on the target edge and propose the node labeling function to identify the role of each node in the subgraph. Then, we leverage graph convolution operation and Sortpooling layer to extract the ﬁxed-size feature from each snapshot/timestamp. Based on the extracted features, we utilize Gated recurrent units ({GRUs}) to capture the temporal information for anomaly detection. Extensive experiments on six benchmark datasets and a real enterprise security system demonstrate the effectiveness of {StrGNN}.},
	number = {{arXiv}:2005.07427},
	publisher = {{arXiv}},
	author = {Cai, Lei and Chen, Zhengzhang and Luo, Chen and Gui, Jiaping and Ni, Jingchao and Li, Ding and Chen, Haifeng},
	urldate = {2023-05-02},
	date = {2020-05-25},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {2005.07427 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Computer Science - Social and Information Networks, Statistics - Machine Learning},
}

@misc{zhang_trustworthy_2022,
	title = {Trustworthy Graph Neural Networks: Aspects, Methods and Trends},
	url = {http://arxiv.org/abs/2205.07424},
	shorttitle = {Trustworthy Graph Neural Networks},
	abstract = {Graph neural networks ({GNNs}) have emerged as a series of competent graph learning methods for diverse real-world scenarios, ranging from daily applications like recommendation systems and question answering to cutting-edge technologies such as drug discovery in life sciences and n-body simulation in astrophysics. However, task performance is not the only requirement for {GNNs}. Performance-oriented {GNNs} have exhibited potential adverse effects like vulnerability to adversarial attacks, unexplainable discrimination against disadvantaged groups, or excessive resource consumption in edge computing environments. To avoid these unintentional harms, it is necessary to build competent {GNNs} characterised by trustworthiness. To this end, we propose a comprehensive roadmap to build trustworthy {GNNs} from the view of the various computing technologies involved. In this survey, we introduce basic concepts and comprehensively summarise existing efforts for trustworthy {GNNs} from six aspects, including robustness, explainability, privacy, fairness, accountability, and environmental well-being. Additionally, we highlight the intricate cross-aspect relations between the above six aspects of trustworthy {GNNs}. Finally, we present a thorough overview of trending directions for facilitating the research and industrialisation of trustworthy {GNNs}.},
	number = {{arXiv}:2205.07424},
	publisher = {{arXiv}},
	author = {Zhang, He and Wu, Bang and Yuan, Xingliang and Pan, Shirui and Tong, Hanghang and Pei, Jian},
	urldate = {2023-05-02},
	date = {2022-05-15},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {2205.07424 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
}

@article{akoglu_graph_2015,
	title = {Graph based anomaly detection and description: a survey},
	volume = {29},
	issn = {1384-5810, 1573-756X},
	url = {http://link.springer.com/10.1007/s10618-014-0365-y},
	doi = {10.1007/s10618-014-0365-y},
	shorttitle = {Graph based anomaly detection and description},
	pages = {626--688},
	number = {3},
	journaltitle = {Data Mining and Knowledge Discovery},
	shortjournal = {Data Min Knowl Disc},
	author = {Akoglu, Leman and Tong, Hanghang and Koutra, Danai},
	urldate = {2022-11-27},
	date = {2015-05},
	langid = {english},
}
