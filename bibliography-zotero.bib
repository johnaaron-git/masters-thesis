
@book{kauermann_statistical_2021,
	location = {Cham},
	title = {Statistical Foundations, Reasoning and Inference: For Science and Data Science},
	isbn = {978-3-030-69826-3 978-3-030-69827-0},
	url = {https://link.springer.com/10.1007/978-3-030-69827-0},
	series = {Springer Series in Statistics},
	shorttitle = {Statistical Foundations, Reasoning and Inference},
	publisher = {Springer International Publishing},
	author = {Kauermann, G√∂ran and K√ºchenhoff, Helmut and Heumann, Christian},
	urldate = {2023-05-15},
	date = {2021},
	langid = {english},
	doi = {10.1007/978-3-030-69827-0},
	keywords = {Bayesian statistics, bootstrapping, causality, data analytics, data science, likelihood-based inference, missing data, multivariate distributions, statistical foundations, statistical inference, statistical reasoning, statistical tests, statistics for data science, uncertainty quantification},
}

@article{kim_temporal_2022,
	title = {Temporal Patterns Discovery of Evolving Graphs for Graph Neural Network ({GNN})-based Anomaly Detection in Heterogeneous Networks},
	volume = {12},
	url = {https://doi.org/10.22667/JISIS.2022.02.28.072},
	doi = {10.22667/JISIS.2022.02.28.072},
	abstract = {This paper proposes a new method named evolving-graph generation framework to simultaneously solve the complexity and dynamic nature of the attribute networks that can occur in graph-based anomaly detection with Graph Neural Networks ({GNN}). The proposed framework consists of two components. The Ô¨Årst component is a feature selection method that hybridizes Ô¨Ålter-based and wrapper-based techniques to reduce the snapshots. The second component is an association method based on temporal patterns for the snapshots using the subgraph embedding technique and gaussian-base {KL} divergence. At the time, the association method Ô¨Ånds intra-snapshots and inter-snapshots associations. As a result, we can obtain an evolving graph that is simpliÔ¨Åed and temporal patterns-enhanced from original networks. It is used an input graph for a {GNN}-based anomaly detection model. To show the superiority of the proposed framework, we conduct experiments and evaluations on 8 real-world datasets with anomaly labels with comparative state-of-the-art models of graph-based anomaly detection. We show that the proposed framework outperforms state-of-the-art methods in the accuracy and stability of training with the trend of decreasing train loss.},
	pages = {72--82},
	number = {1},
	journaltitle = {Journal of Internet Services and Information Security},
	author = {Kim, Jongmo and Kim, Kunyoung and Jeon, Gi-yoon and Sohn, Mye},
	urldate = {2023-05-15},
	date = {2022-02-28},
}

@video{deepfindr_friendly_2021,
	title = {Friendly Introduction to Temporal Graph Neural Networks (and some Traffic Forecasting)},
	url = {https://www.youtube.com/watch?v=WEWq93tioC4},
	abstract = {‚ñ¨‚ñ¨ Papers ‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨
Temporal Graph Networks: https://arxiv.org/pdf/2006.10637.pdf (used for the intro)
Pytorch Geometric Temporal: https://arxiv.org/pdf/2104.07788.pdf
Diffusion Convolutional Recurrent Neural Network: https://arxiv.org/pdf/1707.01926.pdf
{MST}-{GNN}: https://arxiv.org/pdf/2108.11244.pdf


‚ñ¨‚ñ¨ Used Vector Graphics ‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨
All icons and vector graphics used are from www.flaticon.com by these creators:
- Moon, Sensor, Traffic signs: freepik
- Cars: Konkapp, vectorsmarket15, {DinosoftLabs}, Vectors Market
- City: smallikeart
The road vector graphics are from: https://de.vecteezy.com/vektorkunst/1...


‚ñ¨‚ñ¨ Used Music ‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨
Music from Uppbeat (free for Creators!):
https://uppbeat.io/t/genuine-colour/t...
License code: {ONW}3ZGTQBAPMEEFQ


‚ñ¨‚ñ¨ Used Videos ‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨
Pexels:
- Bhargava Marripati 
- Vitaly Vlasov
- Tom Fisk
- Pressmaster
- Tima Miroshnichenko


‚ñ¨‚ñ¨ Used Images ‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨
{DCRNN}: https://arxiv.org/pdf/1707.01926.pdf
Transfer {GNN} for Pandemic forecasting: https://arxiv.org/pdf/2009.08388.pdf
Mediapipe: https://google.github.io/mediapipe/so... 
Solar Power: https://arxiv.org/pdf/2107.13875.pdf


‚ñ¨‚ñ¨ Timestamps ‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨
00:00 Introduction
00:53 Temporal Graphs
02:25 Applications
03:30 Traffic Forecasting Example
08:01 Temporal {GNNs}
11:11 Variants/Papers
12:40 Dynamic Graphs
14:00 Outro


‚ñ¨‚ñ¨ Support me if you like üåü
‚ñ∫Link to this channel: https://bit.ly/3zEqL1W
‚ñ∫Support me on Patreon: https://bit.ly/2Wed242
‚ñ∫Buy me a coffee on Ko-Fi: https://bit.ly/3kJYEdl


‚ñ¨‚ñ¨ My equipment üíª
- Microphone: https://amzn.to/3DVqB8H
- Microphone mount: https://amzn.to/3BWUcOJ
- Monitors: https://amzn.to/3G2Jjgr
- Monitor mount: https://amzn.to/3AWGIAY
- Height-adjustable table: https://amzn.to/3aUysXC
- Ergonomic chair: https://amzn.to/3phQg7r
- {PC} case: https://amzn.to/3jdlI2Y
- {GPU}: https://amzn.to/3AWyzwy
- Keyboard: https://amzn.to/2XskWHP
- Bluelight filter glasses: https://amzn.to/3pj0fK2},
	author = {{DeepFindr}},
	urldate = {2023-05-15},
	date = {2021-12-02},
}

@software{dou_safe-graphdgfraud_2023,
	title = {safe-graph/{DGFraud}},
	rights = {Apache-2.0},
	url = {https://github.com/safe-graph/DGFraud},
	abstract = {A Deep Graph-based Toolbox for Fraud Detection},
	publisher = {{SafeGraph}},
	author = {Dou, Yingtong and Liu, Jim},
	urldate = {2023-05-15},
	date = {2023-05-15},
	note = {original-date: 2019-11-22T14:02:36Z},
	keywords = {anomaly-detection, datamining, datascience, dblp-dataset, financial-engineering, fraud-detection, fraud-prevention, graph, graph-algorithms, graph-convolutional-networks, graph-neural-networks, graphneuralnetwork, machine-learning, opensource, outlier-detection, security, security-tools, spamdetection, toolkit, yelp-dataset},
}

@misc{serrano_is_2019,
	title = {Is Attention Interpretable?},
	url = {http://arxiv.org/abs/1906.03731},
	doi = {10.48550/arXiv.1906.03731},
	abstract = {Attention mechanisms have recently boosted performance on a range of {NLP} tasks. Because attention layers explicitly weight input components' representations, it is also often assumed that attention can be used to identify information that models found important (e.g., specific contextualized word tokens). We test whether that assumption holds by manipulating attention weights in already-trained text classification models and analyzing the resulting differences in their predictions. While we observe some ways in which higher attention weights correlate with greater impact on model predictions, we also find many ways in which this does not hold, i.e., where gradient-based rankings of attention weights better predict their effects than their magnitudes. We conclude that while attention noisily predicts input components' overall importance to a model, it is by no means a fail-safe indicator.},
	number = {{arXiv}:1906.03731},
	publisher = {{arXiv}},
	author = {Serrano, Sofia and Smith, Noah A.},
	urldate = {2023-05-15},
	date = {2019-06-09},
	eprinttype = {arxiv},
	eprint = {1906.03731 [cs]},
	keywords = {Computer Science - Computation and Language},
}

@online{chintala_pytorchpytorch_nodate,
	title = {pytorch/pytorch: Tensors and Dynamic neural networks in Python with strong {GPU} acceleration},
	url = {https://github.com/pytorch/pytorch},
	shorttitle = {pytorch/pytorch},
	author = {Chintala, Soumith and Chanan, Gregory},
	urldate = {2023-05-15},
	langid = {english},
}

@online{dive_lab_dig_nodate,
	title = {{DIG}: Dive into Graphs Documentation ‚Äî {DIG}: Dive into Graphs 1.0.0 documentation},
	url = {https://diveintographs.readthedocs.io/en/latest/},
	author = {{DIVE} Lab},
	urldate = {2023-05-15},
}

@article{liu_contrast_2019,
	title = {A Contrast Metric for Fraud Detection in Rich Graphs},
	volume = {31},
	issn = {1041-4347, 1558-2191, 2326-3865},
	url = {https://ieeexplore.ieee.org/document/8494803/},
	doi = {10.1109/TKDE.2018.2876531},
	abstract = {How can we detect fraud in a big graph with rich properties, as online fraudsters invest more resources, including purchasing large pools of fake user accounts and dedicated {IPs}, to hide their fraudulent attacks? To achieve robustness, existing approaches detected dense sub-graphs as suspicious patterns in an unsupervised way, such as average degree maximization. However, such approaches suffer from the bias of including more nodes than necessary, resulting in lower accuracy and increased need for manual veriÔ¨Åcation. Therefore, we propose {HoloScope}, which introduces a novel metric ‚Äúcontrast suspiciousness‚Äù integrating information from graph topology and spikes to more accurately detect fraudulent users and objects. Contrast suspiciousness dynamically emphasizes the contrasting patterns between fraudsters and normal users, making {HoloScope} capable of distinguishing the synchronized and strange behaviors of fraudsters by means of topology, bursts and drops, and rating scores. In addition, we provide theoretical bounds for how much this method increases the time cost needed for fraudsters to conduct adversarial attacks. Moreover, {HoloScope} has a concise framework and sub-quadratic time complexity, making the algorithm reproducible and scalable. In extensive experiments, {HoloScope} achieved signiÔ¨Åcant accuracy improvements on real data with injected labels and true labels, when compared with state-of-the-art fraud detection methods.},
	pages = {2235--2248},
	number = {12},
	journaltitle = {{IEEE} Transactions on Knowledge and Data Engineering},
	shortjournal = {{IEEE} Trans. Knowl. Data Eng.},
	author = {Liu, Shenghua and Hooi, Bryan and Faloutsos, Christos},
	urldate = {2023-05-15},
	date = {2019-12-01},
	langid = {english},
}

@online{leskovec_cs224w_2023,
	title = {{CS}224W: Machine Learning with Graphs},
	url = {https://web.stanford.edu/class/cs224w/},
	titleaddon = {Stanford {SNAP} online},
	author = {Leskovec, Jure},
	date = {2023},
}

@software{liu_pygod-teampygod_2023,
	title = {pygod-team/pygod},
	rights = {{BSD}-2-Clause},
	url = {https://github.com/pygod-team/pygod},
	abstract = {A Python Library for Graph Outlier Detection (Anomaly Detection)},
	publisher = {{PyGOD} Team},
	author = {Liu, Kay},
	urldate = {2023-05-15},
	date = {2023-05-14},
	note = {original-date: 2021-11-18T23:18:17Z},
	keywords = {anomaly-detection, deeplearning, fraud-detection, graph-anomaly-detection, graph-neural-networks, graphmining, machine-learning, opensource, outlier-detection, python, pytorch, security-tools, toolkit},
}

@online{karthika_gcn_2021,
	title = {{GCN} on elliptic dataset},
	url = {https://kaggle.com/code/karthikapv/gcn-elliptic-dataset},
	author = {Karthika, {PV}},
	urldate = {2023-05-14},
	date = {2021},
	langid = {english},
}

@online{soto_fraud_2021,
	title = {Fraud Detection System on Elliptic Dataset},
	url = {https://kaggle.com/code/guyensoto/fraud-detection-system},
	author = {Soto, Guyen},
	urldate = {2023-05-14},
	date = {2021},
	langid = {english},
}

@online{yang_transfer_2020,
	title = {Transfer Learning evolve {GCN} for {AML}},
	url = {https://kaggle.com/code/diyang/transfer-learning-evolve-gcn-for-aml},
	abstract = {Explore and run machine learning code with Kaggle Notebooks {\textbar} Using data from multiple data sources},
	author = {Yang, Di},
	urldate = {2023-05-14},
	date = {2020},
	langid = {english},
}

@inproceedings{lopez-rojas_banksim_2014,
	title = {{BankSim}: A Bank Payment Simulation for Fraud Detection Research},
	shorttitle = {{BankSim}},
	abstract = {{BankSim} is an agent-based simulator of bank payments based on a sample of aggregated transactional data provided by a bank in Spain. The main purpose of {BankSim} is the generation of synthetic data that can be used for fraud detection research. Statistical and a Social Network Analysis ({SNA}) of relations between merchants and customers were used to develop and calibrate the model. Our ultimate goal is for {BankSim} to be usable to model relevant scenarios that combine normal payments and injected known fraud signatures. The data sets generated by
{BankSim} contain no personal information or disclosure of legal and private customer transactions. Therefore, it can be shared by
academia, and others, to develop and reason about fraud detection methods. Synthetic data has the added benefit of being easier to
acquire, faster and at less cost, for experimentation even for those that have access to their own data. We argue that {BankSim}
generates data that usefully approximates the relevant aspects of the real data. We intend to make the simulation and its results available to the research community.},
	eventtitle = {26th European Modeling and Simulation Symposium, {EMSS} 2014},
	author = {Lopez-Rojas, Edgar Alonso and Axelsson, Stefan},
	date = {2014-09-10},
}

@article{lopez-rojas_applying_2016,
	title = {Applying Simulation to the Problem of Detecting Financial Fraud},
	url = {https://urn.kb.se/resolve?urn=urn:nbn:se:bth-12932},
	abstract = {This thesis introduces a financial simulation model covering two related financial domains: Mobile Payments and Retail Stores systems.¬†The problem we address in these domains is different types of  ...},
	author = {Lopez-Rojas, Edgar Alonso},
	urldate = {2023-05-14},
	date = {2016},
	note = {Publisher: Blekinge Tekniska H√∂gskola},
}

@online{barroso_interbank_2016,
	title = {Interbank network and regulation policies: an analysis through agent-based simulations with adaptive learning},
	url = {https://mpra.ub.uni-muenchen.de/73308/},
	shorttitle = {Interbank network and regulation policies},
	abstract = {We develop an agent-based model to study the impacts of a broad range of regulation policies over the banking system. It builds on an iterated version of the {\textbackslash}citet\{{DiamondDybvig}1983\} framework and resorts to the experience-weighted attraction learning scheme of {\textbackslash}citet\{{CamererHo}1999\} to model agents' adaptive learning. Thereby, we can capture not only the direct impacts of regulation policies, but also the ones that take part through shifting agents' adaptive strategies. Our results show that the introduction of an interbank clearinghouse is a good instrument to face the risk of contagion; the regulatory guidelines of the Basel Accord are effective in reducing the probability of bank failure; and the adoption of a deposit insurance can be adequate to avoid bank runs. However, we also show that these policies have drawbacks, and can either reduce bank activity or stimulate moral hazard.},
	type = {{MPRA} Paper},
	author = {Barroso, Ricardo Vieira and Lima, Joaquim Ignacio Alves Vasconcellos and Lucchetti, Alexandre Henrique and Cajueiro, Daniel Oliveira},
	urldate = {2023-05-14},
	date = {2016-07-15},
	langid = {english},
	note = {https://www.kaggle.com/datasets/ealaxi/banksim1},
}

@misc{weber_anti-money_2019,
	title = {Anti-Money Laundering in Bitcoin: Experimenting with Graph Convolutional Networks for Financial Forensics},
	url = {http://arxiv.org/abs/1908.02591},
	doi = {10.48550/arXiv.1908.02591},
	shorttitle = {Anti-Money Laundering in Bitcoin},
	abstract = {Anti-money laundering ({AML}) regulations play a critical role in safeguarding financial systems, but bear high costs for institutions and drive financial exclusion for those on the socioeconomic and international margins. The advent of cryptocurrency has introduced an intriguing paradox: pseudonymity allows criminals to hide in plain sight, but open data gives more power to investigators and enables the crowdsourcing of forensic analysis. Meanwhile advances in learning algorithms show great promise for the {AML} toolkit. In this workshop tutorial, we motivate the opportunity to reconcile the cause of safety with that of financial inclusion. We contribute the Elliptic Data Set, a time series graph of over 200K Bitcoin transactions (nodes), 234K directed payment flows (edges), and 166 node features, including ones based on non-public data; to our knowledge, this is the largest labelled transaction data set publicly available in any cryptocurrency. We share results from a binary classification task predicting illicit transactions using variations of Logistic Regression ({LR}), Random Forest ({RF}), Multilayer Perceptrons ({MLP}), and Graph Convolutional Networks ({GCN}), with {GCN} being of special interest as an emergent new method for capturing relational information. The results show the superiority of Random Forest ({RF}), but also invite algorithmic work to combine the respective powers of {RF} and graph methods. Lastly, we consider visualization for analysis and explainability, which is difficult given the size and dynamism of real-world transaction graphs, and we offer a simple prototype capable of navigating the graph and observing model performance on illicit activity over time. With this tutorial and data set, we hope to a) invite feedback in support of our ongoing inquiry, and b) inspire others to work on this societally important challenge.},
	number = {{arXiv}:1908.02591},
	publisher = {{arXiv}},
	author = {Weber, Mark and Domeniconi, Giacomo and Chen, Jie and Weidele, Daniel Karl I. and Bellei, Claudio and Robinson, Tom and Leiserson, Charles E.},
	urldate = {2023-05-14},
	date = {2019-07-31},
	eprinttype = {arxiv},
	eprint = {1908.02591 [cs, q-fin]},
	keywords = {Computer Science - Computers and Society, Computer Science - Machine Learning, Computer Science - Social and Information Networks, Quantitative Finance - General Finance},
}

@article{narayan_learning_2018,
	title = {Learning Graph Dynamics using Deep Neural Networks},
	volume = {51},
	issn = {2405-8963},
	url = {https://www.sciencedirect.com/science/article/pii/S2405896318300788},
	doi = {10.1016/j.ifacol.2018.03.074},
	series = {9th Vienna International Conference on Mathematical Modelling},
	abstract = {A large number of real-world problems have high dimensional data. The data obtained from these problems is highly structured and usually in the form of graphs. Graphs represent spatial information about the system in the form of vertices and edges. Often graphs evolve with time and the underlying system exhibits dynamic behavior. Hence, these graphs contain both spatial and temporal information about the system. Understanding, visualizing, and learning large graphs is of key importance for understanding the underlying system and is a challenging task due to the data deluge problem. Our work here utilizes both spatial and temporal information from structured graphs. We learn spatial and temporal information using a specific type of neural network model. Our model is robust to the kind of graphs and their dynamics of evolution. Our approach is scalable to not only the size of the graph (number of vertices and edges) but also the number of attributes (features) of the data. We show that our approach is simple, generic, parallelizable, and performs at-par with the state-of-the-art techniques. We also compare the results of our model against other existing techniques.},
	pages = {433--438},
	number = {2},
	journaltitle = {{IFAC}-{PapersOnLine}},
	shortjournal = {{IFAC}-{PapersOnLine}},
	author = {Narayan, Apurva and O‚ÄôN Roe, Peter H.},
	urldate = {2023-05-14},
	date = {2018-01-01},
	langid = {english},
	keywords = {Deep Learning, Graph Theory, Learning Graphs},
}

@online{noauthor_fraud_nodate,
	title = {Fraud Detection System},
	url = {https://kaggle.com/code/guyensoto/fraud-detection-system},
	abstract = {Explore and run machine learning code with Kaggle Notebooks {\textbar} Using data from Elliptic Data Set},
	urldate = {2023-05-14},
	langid = {english},
}

@article{liu_anomaly_2021,
	title = {Anomaly Detection in Dynamic Graphs via Transformer},
	issn = {1558-2191},
	doi = {10.1109/TKDE.2021.3124061},
	abstract = {Detecting anomalies for dynamic graphs has drawn increasing attention due to their wide applications in social networks, e-commerce, and cybersecurity. Recent deep learning-based approaches have shown promising results over shallow methods. However, they fail to address two core challenges of anomaly detection in dynamic graphs: the lack of informative encoding for unattributed nodes and the difficulty of learning discriminate knowledge from coupled spatial-temporal dynamic graphs. To overcome these challenges, in this paper, we present a novel transformer-based Anomaly Detection framework for dynamic graphs ({TADDY}). Our framework constructs a comprehensive node encoding strategy to better represent each nodes structural and temporal roles in an evolving graphs stream. Meanwhile, {TADDY} captures informative representation from dynamic graphs with coupled spatial-temporal patterns via a dynamic graph transformer model. The extensive experimental results demonstrate that our proposed {TADDY} framework outperforms the state-of-the-art methods by a large margin on six real-world datasets.},
	pages = {1--1},
	journaltitle = {{IEEE} Transactions on Knowledge and Data Engineering},
	author = {Liu, Yixin and Pan, Shirui and Wang, Yu Guang and Xiong, Fei and Wang, Liang and Chen, Qingfeng and Lee, Vincent {CS}},
	date = {2021},
	note = {Conference Name: {IEEE} Transactions on Knowledge and Data Engineering},
	keywords = {Anomaly detection, Encoding, Feature extraction, Image edge detection, Solid modeling, Task analysis, Transformers, dynamic graphs, transformer},
}

@inproceedings{zhu_flexible_2020,
	title = {A Flexible Attentive Temporal Graph Networks for Anomaly Detection in Dynamic Networks},
	doi = {10.1109/TrustCom50675.2020.00117},
	abstract = {Anomaly Detection in Dynamic Networks plays a critical role in various real-world applications such as cyberse-curity, e-commerce, and social media. Recent approaches based on graph neural networks have achieved fruitful results in static networks, and most of the researches focus on learning node embeddings to represent the large-scale complex networks, thereby facilitating downstream anomaly detection task. However, these methods require the whole network to extract intrinsic properties, so they are sensitive to the frequent changes of nodes and incapable of capturing the dynamism as realworld networks evolve over time. In this paper, we propose a novel framework {DynAD} for anomalous edge detection on time-evolving networks, which performs adaptive parameter learning in an end-to-end manner. In particular, {DynAD} first extracts fixed-size node embedding from each snapshot with temporal graph convolution and pooling operations. Then, it captures the temporal information of the graph sequence using Gated recurrent units ({GRU}) for anomaly detection, where an attention mechanism is employed to highlight the differences between the dynamic patterns. Experimental results on three real-world datasets illustrate that {DynAD} significantly outperforms the state-of-the-art baseline methods in anomaly detection.},
	eventtitle = {2020 {IEEE} 19th International Conference on Trust, Security and Privacy in Computing and Communications ({TrustCom})},
	pages = {870--875},
	booktitle = {2020 {IEEE} 19th International Conference on Trust, Security and Privacy in Computing and Communications ({TrustCom})},
	author = {Zhu, Dali and Ma, Yuchen and Liu, Yinlong},
	date = {2020-12},
	note = {{ISSN}: 2324-9013},
	keywords = {Adaptation models, Adaptive systems, Anomaly Detection, Dynamic Networks, Graph Embedding, Graph Convolutional Network, Anomaly detection, Feature extraction, Social networking (online), Task analysis, Training},
}

@article{toshniwal_hypergraph_2021,
	title = {Hypergraph based Unsupervised Contextual Pattern Learning and Anomaly Detection for Global Terrorism Data},
	volume = {1950},
	rights = {¬© 2021. This work is published under http://creativecommons.org/licenses/by/3.0/ (the ‚ÄúLicense‚Äù). Notwithstanding the {ProQuest} Terms and Conditions, you may use this content in accordance with the terms of the License.},
	issn = {17426588},
	url = {https://www.proquest.com/docview/2559689885/abstract/7DFA9B7840EC443DPQ/1},
	doi = {10.1088/1742-6596/1950/1/012066},
	abstract = {In a dataset, an event which deviates from the rest of the dataset is a rare event. This rare event can be intrusion or any suspicious activity in the system and is called an anomaly. These anomalies are important to detect because this may be any terrorist attack, outbreak of the disease, malfunctioning or fraud in the system. Anomalies are the deviation from the normal patterns in the dataset. It is important to learn the normal patterns in order to identify the deviation. Labelled data in real life anomaly detection is not available due to rarity of anomalies. It is challenging to identify anomalous combinations and combinatorial patterns of feature instances using conventional machine learning algorithms. We introduce Hypergraph based Unsupervised Contextual Pattern Learning and Anomaly Detection ({HUCPLAD}) technique for unlabeled datasets and implemented on Global Terrorism Data ({GTD}). {HUCPLAD} gets rid of the curse of dimensionality, maintains hierarchy, learns the contextual pattern, detects contextual anomalies and measures the behavior of co-occurring events.},
	number = {1},
	journaltitle = {Journal of Physics: Conference Series},
	author = {Toshniwal, Akanksha and Mahesh, Kavi and Jayashree, R.},
	urldate = {2023-05-13},
	date = {2021-08},
	note = {Place: Bristol, United Kingdom
Publisher: {IOP} Publishing},
	keywords = {Algorithms, Anomalies, Combinatorial analysis, Datasets, Deviation, Fraud, Graph theory, Graphs, Machine learning, Physics, Terrorism},
}

@online{benson_cornell_nodate,
	title = {Cornell Temporal Hypergraph Datasets},
	url = {https://www.cs.cornell.edu/~arb/data/},
	author = {Benson, Austin},
	urldate = {2023-05-13},
}

@article{casteigts_time-varying_2012,
	title = {Time-varying graphs and dynamic networks},
	volume = {27},
	issn = {1744-5760},
	url = {https://doi.org/10.1080/17445760.2012.668546},
	doi = {10.1080/17445760.2012.668546},
	abstract = {The past few years have seen intensive research efforts carried out in some apparently unrelated areas of dynamic systems ‚Äì delay-tolerant networks, opportunistic-mobility networks and social networks ‚Äì obtaining closely related insights. Indeed, the concepts discovered in these investigations can be viewed as parts of the same conceptual universe, and the formal models proposed so far to express some specific concepts are the components of a larger formal description of this universe. The main contribution of this paper is to integrate the vast collection of concepts, formalisms and results found in the literature into a unified framework, which we call time-varying graphs ({TVGs}). Using this framework, it is possible to express directly in the same formalism not only the concepts common to all those different areas, but also those specific to each. Based on this definitional work, employing both existing results and original observations, we present a hierarchical classification of {TVGs}; each class corresponds to a significant property examined in the distributed computing literature. We then examine how {TVGs} can be used to study the evolution of network properties, and propose different techniques, depending on whether the indicators for these properties are atemporal (as in the majority of existing studies) or temporal. Finally, we briefly discuss the introduction of randomness in {TVGs}.},
	pages = {387--408},
	number = {5},
	journaltitle = {International Journal of Parallel, Emergent and Distributed Systems},
	author = {Casteigts, Arnaud and Flocchini, Paola and Quattrociocchi, Walter and Santoro, Nicola},
	urldate = {2023-05-13},
	date = {2012-10-01},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/17445760.2012.668546},
	keywords = {delay-tolerant networks, distributed computing, dynamic graphs, opportunistic networks, social networks, time-varying graphs},
}

@inproceedings{putelli_attention-based_2021,
	location = {Cham},
	title = {Attention-Based Explanation in a Deep Learning Model For Classifying Radiology Reports},
	isbn = {978-3-030-77211-6},
	doi = {10.1007/978-3-030-77211-6_42},
	series = {Lecture Notes in Computer Science},
	abstract = {Although deep learning techniques have obtained remarkable results in clinical text analysis, the delicacy of this application domain requires also that these models can be easily understood by the hospital staff. The attention mechanism, which assigns numerical weights representing the contribution of each word to the predictive task, can be exploited for identifying the textual evidence the prediction is based on. In this paper, we investigate the explainability of an attention-based classification model for radiology reports collected from an Italian hospital. The identified explanations are compared with a set of manual annotations made by the domain experts in order to analyze the usefulness of the attention mechanism in our context.},
	pages = {367--372},
	booktitle = {Artificial Intelligence in Medicine},
	publisher = {Springer International Publishing},
	author = {Putelli, Luca and Gerevini, Alfonso E. and Lavelli, Alberto and Maroldi, Roberto and Serina, Ivan},
	editor = {Tucker, Allan and Henriques Abreu, Pedro and Cardoso, Jaime and Pereira Rodrigues, Pedro and Ria√±o, David},
	date = {2021},
	langid = {english},
}

@inproceedings{yuan_xgnn_2020,
	title = {{XGNN}: Towards Model-Level Explanations of Graph Neural Networks},
	url = {http://arxiv.org/abs/2006.02587},
	doi = {10.1145/3394486.3403085},
	shorttitle = {{XGNN}},
	abstract = {Graphs neural networks ({GNNs}) learn node features by aggregating and combining neighbor information, which have achieved promising performance on many graph tasks. However, {GNNs} are mostly treated as black-boxes and lack human intelligible explanations. Thus, they cannot be fully trusted and used in certain application domains if {GNN} models cannot be explained. In this work, we propose a novel approach, known as {XGNN}, to interpret {GNNs} at the model-level. Our approach can provide high-level insights and generic understanding of how {GNNs} work. In particular, we propose to explain {GNNs} by training a graph generator so that the generated graph patterns maximize a certain prediction of the model.We formulate the graph generation as a reinforcement learning task, where for each step, the graph generator predicts how to add an edge into the current graph. The graph generator is trained via a policy gradient method based on information from the trained {GNNs}. In addition, we incorporate several graph rules to encourage the generated graphs to be valid. Experimental results on both synthetic and real-world datasets show that our proposed methods help understand and verify the trained {GNNs}. Furthermore, our experimental results indicate that the generated graphs can provide guidance on how to improve the trained {GNNs}.},
	pages = {430--438},
	booktitle = {Proceedings of the 26th {ACM} {SIGKDD} International Conference on Knowledge Discovery \& Data Mining},
	author = {Yuan, Hao and Tang, Jiliang and Hu, Xia and Ji, Shuiwang},
	urldate = {2023-05-13},
	date = {2020-08-23},
	eprinttype = {arxiv},
	eprint = {2006.02587 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{crichton_neural_2018,
	title = {Neural networks for link prediction in realistic biomedical graphs: a multi-dimensional evaluation of graph embedding-based approaches},
	volume = {19},
	issn = {1471-2105},
	url = {https://doi.org/10.1186/s12859-018-2163-9},
	doi = {10.1186/s12859-018-2163-9},
	shorttitle = {Neural networks for link prediction in realistic biomedical graphs},
	abstract = {Link prediction in biomedical graphs has several important applications including predicting Drug-Target Interactions ({DTI}), Protein-Protein Interaction ({PPI}) prediction and Literature-Based Discovery ({LBD}). It can be done using a classifier to output the probability of link formation between nodes. Recently several works have used neural networks to create node representations which allow rich inputs to neural classifiers. Preliminary works were done on this and report promising results. However they did not use realistic settings like time-slicing, evaluate performances with comprehensive metrics or explain when or why neural network methods outperform. We investigated how inputs from four node representation algorithms affect performance of a neural link predictor on random- and time-sliced biomedical graphs of real-world sizes (‚àº‚Äâ6 million edges) containing information relevant to {DTI}, {PPI} and {LBD}. We compared the performance of the neural link predictor to those of established baselines and report performance across five metrics.},
	pages = {176},
	number = {1},
	journaltitle = {{BMC} Bioinformatics},
	shortjournal = {{BMC} Bioinformatics},
	author = {Crichton, Gamal and Guo, Yufan and Pyysalo, Sampo and Korhonen, Anna},
	urldate = {2023-05-13},
	date = {2018-05-21},
	keywords = {Data mining, Drug-target interaction, Link prediction, Literature-based discovery, Neural networks},
}

@inproceedings{george_time-aggregated_2006,
	location = {Berlin, Heidelberg},
	title = {Time-Aggregated Graphs for Modeling Spatio-temporal Networks},
	isbn = {978-3-540-47704-4},
	doi = {10.1007/11908883_12},
	series = {Lecture Notes in Computer Science},
	abstract = {Given applications such as location based services and the spatio-temporal queries they may pose on a spatial network (eg. road networks), the goal is to develop a simple and expressive model that honors the time dependence of the road network. The model must support the design of efficient algorithms for computing the frequent queries on the network. This problem is challenging due to potentially conflicting requirements of model simplicity and support for efficient algorithms. Time expanded networks which have been used to model dynamic networks employ replication of the network across time instants, resulting in high storage overhead and algorithms that are computationally expensive. In contrast, the proposed time-aggregated graphs do not replicate nodes and edges across time; rather they allow the properties of edges and nodes to be modeled as a time series. Since the model does not replicate the entire graph for every instant of time, it uses less memory and the algorithms for common operations (e.g. connectivity, shortest path) are computationally more efficient than the time expanded networks.},
	pages = {85--99},
	booktitle = {Advances in Conceptual Modeling - Theory and Practice},
	publisher = {Springer},
	author = {George, Betsy and Shekhar, Shashi},
	editor = {Roddick, John F. and Benjamins, V. Richard and Si-said Cherfi, Samira and Chiang, Roger and Claramunt, Christophe and Elmasri, Ramez A. and Grandi, Fabio and Han, Hyoil and Hepp, Martin and Lytras, Miltiadis D. and Mi≈°iƒá, Vojislav B. and Poels, Geert and Song, Il-Yeol and Trujillo, Juan and Vangenot, Christelle},
	date = {2006},
	langid = {english},
	keywords = {Time-aggregated graphs, location based services, shortest paths, spatio-temporal data-bases},
}

@online{fallenvalkyrie_tensors_2021,
	title = {Tensors in Pytorch},
	url = {https://www.geeksforgeeks.org/tensors-in-pytorch/},
	abstract = {A Computer Science portal for geeks. It contains well written, well thought and well explained computer science and programming articles, quizzes and practice/competitive programming/company interview Questions.},
	titleaddon = {{GeeksforGeeks}},
	author = {fallenvalkyrie},
	urldate = {2023-05-12},
	date = {2021-07-02},
	langid = {english},
	note = {Section: Python},
}

@online{pyg_team_pyg_nodate,
	title = {{PyG} Documentation ‚Äî pytorch\_geometric documentation},
	url = {https://pytorch-geometric.readthedocs.io/en/latest/},
	author = {{PyG} Team},
	urldate = {2023-05-12},
}

@misc{yao_interpretable_2021,
	title = {Interpretable Clustering on Dynamic Graphs with Recurrent Graph Neural Networks},
	url = {http://arxiv.org/abs/2012.08740},
	doi = {10.48550/arXiv.2012.08740},
	abstract = {We study the problem of clustering nodes in a dynamic graph, where the connections between nodes and nodes' cluster memberships may change over time, e.g., due to community migration. We first propose a dynamic stochastic block model that captures these changes, and a simple decay-based clustering algorithm that clusters nodes based on weighted connections between them, where the weight decreases at a fixed rate over time. This decay rate can then be interpreted as signifying the importance of including historical connection information in the clustering. However, the optimal decay rate may differ for clusters with different rates of turnover. We characterize the optimal decay rate for each cluster and propose a clustering method that achieves almost exact recovery of the true clusters. We then demonstrate the efficacy of our clustering algorithm with optimized decay rates on simulated graph data. Recurrent neural networks ({RNNs}), a popular algorithm for sequence learning, use a similar decay-based method, and we use this insight to propose two new {RNN}-{GCN} (graph convolutional network) architectures for semi-supervised graph clustering. We finally demonstrate that the proposed architectures perform well on real data compared to state-of-the-art graph clustering algorithms.},
	number = {{arXiv}:2012.08740},
	publisher = {{arXiv}},
	author = {Yao, Yuhang and Joe-Wong, Carlee},
	urldate = {2023-05-09},
	date = {2021-06-22},
	eprinttype = {arxiv},
	eprint = {2012.08740 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Social and Information Networks},
}

@article{lindemann_survey_2021,
	title = {A survey on anomaly detection for technical systems using {LSTM} networks},
	volume = {131},
	issn = {0166-3615},
	url = {https://www.sciencedirect.com/science/article/pii/S0166361521001056},
	doi = {10.1016/j.compind.2021.103498},
	abstract = {Anomalies represent deviations from the intended system operation and can lead to decreased efficiency as well as partial or complete system failure. As the causes of anomalies are often unknown due to complex system dynamics, efficient anomaly detection is necessary. Conventional detection approaches rely on statistical and time-invariant methods that fail to address the complex and dynamic nature of anomalies. With advances in artificial intelligence and increasing importance for anomaly detection and prevention in various domains, artificial neural network approaches enable the detection of more complex anomaly types while considering temporal and contextual characteristics. In this article, a survey on state-of-the-art anomaly detection using deep neural and especially long short-term memory networks is conducted. The investigated approaches are evaluated based on the application scenario, data and anomaly types as well as further metrics. To highlight the potential of upcoming anomaly detection techniques, graph-based and transfer learning approaches are also included in the survey, enabling the analysis of heterogeneous data as well as compensating for its shortage and improving the handling of dynamic processes.},
	pages = {103498},
	journaltitle = {Computers in Industry},
	shortjournal = {Computers in Industry},
	author = {Lindemann, Benjamin and Maschler, Benjamin and Sahlab, Nada and Weyrich, Michael},
	urldate = {2023-05-10},
	date = {2021-10-01},
	langid = {english},
	keywords = {Anomaly detection, Artificial intelligence, Autoencoder, Context modeling, Long short-term memory, Transfer learning},
}

@article{zhang_network_2020,
	title = {Network Representation Learning: A Survey},
	volume = {6},
	issn = {2332-7790},
	doi = {10.1109/TBDATA.2018.2850013},
	abstract = {With the widespread use of information technologies, information networks are becoming increasingly popular to capture complex relationships across various disciplines, such as social networks, citation networks, telecommunication networks, and biological networks. Analyzing these networks sheds light on different aspects of social life such as the structure of societies, information diffusion, and communication patterns. In reality, however, the large scale of information networks often makes network analytic tasks computationally expensive or intractable. Network representation learning has been recently proposed as a new learning paradigm to embed network vertices into a low-dimensional vector space, by preserving network topology structure, vertex content, and other side information. This facilitates the original network to be easily handled in the new vector space for further analysis. In this survey, we perform a comprehensive review of the current literature on network representation learning in the data mining and machine learning field. We propose new taxonomies to categorize and summarize the state-of-the-art network representation learning techniques according to the underlying learning mechanisms, the network information intended to preserve, as well as the algorithmic designs and methodologies. We summarize evaluation protocols used for validating network representation learning including published benchmark datasets, evaluation methods, and open source algorithms. We also perform empirical studies to compare the performance of representative algorithms on common datasets, and analyze their computational complexity. Finally, we suggest promising research directions to facilitate future study.},
	pages = {3--28},
	number = {1},
	journaltitle = {{IEEE} transactions on big data},
	shortjournal = {{TBData}},
	author = {Zhang, Daokun and Yin, Jie and Zhu, Xingquan and Zhang, Chengqi},
	date = {2020},
	note = {Place: {PISCATAWAY}
Publisher: {IEEE}},
	keywords = {Algorithms, Apexes, Big Data, Biology, Citation analysis, Complexity, Computer Science, Computer Science, Information Systems, Computer Science, Theory \& Methods, Data mining, Datasets, Empirical analysis, Information dissemination, Information networks, Literature reviews, Machine learning, Machine learning algorithms, Network analysis, Network topologies, Protocol (computers), Representations, Science \& Technology, Social network services, Social networks, Sparse matrices, Task analysis, Taxonomy, Technology, graph mining, network embedding, network representation learning},
}

@article{grant_show_2020,
	title = {Show Us the Data: Privacy, Explainability, and Why the Law Can't Have Both Fall 2019 Symposium: Lessons Learned from Windy Times at the Interface among International Trade, Intellectual Property, Antitrust, and Financial Regulation},
	volume = {88},
	url = {https://heinonline.org/HOL/P?h=hein.journals/gwlr88&i=1433},
	shorttitle = {Show Us the Data},
	pages = {1350--1420},
	number = {6},
	journaltitle = {George Washington Law Review},
	shortjournal = {Geo. Wash. L. Rev.},
	author = {Grant, Thomas D. and Wischik, Damon J.},
	urldate = {2023-05-11},
	date = {2020},
}

@article{van_der_veer_trading_2021,
	title = {Trading off accuracy and explainability in {AI} decision-making: findings from 2 citizens‚Äô juries},
	volume = {28},
	issn = {1527-974X},
	url = {https://doi.org/10.1093/jamia/ocab127},
	doi = {10.1093/jamia/ocab127},
	abstract = {To investigate how the general public trades off explainability versus accuracy of artificial intelligence ({AI}) systems and whether this differs between healthcare and non-healthcare scenarios.Citizens‚Äô juries are a form of deliberative democracy eliciting informed judgment from a representative sample of the general public around policy questions. We organized two 5-day citizens‚Äô juries in the {UK} with 18 jurors each. Jurors considered 3 {AI} systems with different levels of accuracy and explainability in 2 healthcare and 2 non-healthcare scenarios. Per scenario, jurors voted for their preferred system; votes were analyzed descriptively. Qualitative data on considerations behind their preferences included transcribed audio-recordings of plenary sessions, observational field notes, outputs from small group work and free-text comments accompanying jurors‚Äô votes; qualitative data were analyzed thematically by scenario, per and across {AI} systems.In healthcare scenarios, jurors favored accuracy over explainability, whereas in non-healthcare contexts they either valued explainability equally to, or more than, accuracy. Jurors‚Äô considerations in favor of accuracy regarded the impact of decisions on individuals and society, and the potential to increase efficiency of services. Reasons for emphasizing explainability included increased opportunities for individuals and society to learn and improve future prospects and enhanced ability for humans to identify and resolve system biases.Citizens may value explainability of {AI} systems in healthcare less than in non-healthcare domains and less than often assumed by professionals, especially when weighed against system accuracy. The public should therefore be actively consulted when developing policy on {AI} explainability.},
	pages = {2128--2138},
	number = {10},
	journaltitle = {Journal of the American Medical Informatics Association},
	shortjournal = {Journal of the American Medical Informatics Association},
	author = {van der Veer, Sabine N and Riste, Lisa and Cheraghi-Sohi, Sudeh and Phipps, Denham L and Tully, Mary P and Bozentko, Kyle and Atwood, Sarah and Hubbard, Alex and Wiper, Carl and Oswald, Malcolm and Peek, Niels},
	urldate = {2023-05-10},
	date = {2021-10-01},
}

@inproceedings{bell_its_2022,
	location = {New York, {NY}, {USA}},
	title = {It‚Äôs Just Not That Simple: An Empirical Study of the Accuracy-Explainability Trade-off in Machine Learning for Public Policy},
	isbn = {978-1-4503-9352-2},
	url = {https://dl.acm.org/doi/10.1145/3531146.3533090},
	doi = {10.1145/3531146.3533090},
	series = {{FAccT} '22},
	shorttitle = {It‚Äôs Just Not That Simple},
	abstract = {To achieve high accuracy in machine learning ({ML}) systems, practitioners often use complex ‚Äúblack-box‚Äù models that are not easily understood by humans. The opacity of such models has resulted in public concerns about their use in high-stakes contexts and given rise to two conflicting arguments about the nature ‚Äî and even the existence ‚Äî of the accuracy-explainability trade-off. One side postulates that model accuracy and explainability are inversely related, leading practitioners to use black-box models when high accuracy is important. The other side of this argument holds that the accuracy-explainability trade-off is rarely observed in practice and consequently, that simpler interpretable models should always be preferred. Both sides of the argument operate under the assumption that some types of models, such as low-depth decision trees and linear regression are more explainable, while others such as neural networks and random forests, are inherently opaque. Our main contribution is an empirical quantification of the trade-off between model accuracy and explainability in two real-world policy contexts. We quantify explainability in terms of how well a model is understood by a human-in-the-loop ({HITL}) using a combination of objectively measurable criteria, such as a human‚Äôs ability to anticipate a model‚Äôs output or identify the most important feature of a model, and subjective measures, such as a human‚Äôs perceived understanding of the model. Our key finding is that explainability is not directly related to whether a model is a black-box or interpretable and is more nuanced than previously thought. We find that black-box models may be as explainable to a {HITL} as interpretable models and identify two possible reasons: (1) that there are weaknesses in the intrinsic explainability of interpretable models and (2) that more information about a model may confuse users, leading them to perform worse on objectively measurable explainability tasks. In summary, contrary to both positions in the literature, we neither observed a direct trade-off between accuracy and explainability nor found interpretable models to be superior in terms of explainability. It‚Äôs just not that simple!},
	pages = {248--266},
	booktitle = {2022 {ACM} Conference on Fairness, Accountability, and Transparency},
	publisher = {Association for Computing Machinery},
	author = {Bell, Andrew and Solano-Kamaiko, Ian and Nov, Oded and Stoyanovich, Julia},
	urldate = {2023-05-11},
	date = {2022-06-20},
	keywords = {explainability, machine learning, public policy, responsible {AI}},
}

@article{deeks_judicial_2019,
	title = {{THE} {JUDICIAL} {DEMAND} {FOR} {EXPLAINABLE} {ARTIFICIAL} {INTELLIGENCE}},
	volume = {119},
	issn = {00101958, 19452268},
	url = {https://www-jstor-org.kuleuven.e-bronnen.be/stable/26810851},
	abstract = {[A recurrent concern about machine learning algorithms is that they operate as ‚Äúblack boxes,‚Äù making it difficult to identify how and why the algorithms reach particular decisions, recommendations, or predictions. Yet judges are confronting machine learning algorithms with increasing frequency, including in criminal, administrative, and civil cases. This Essay argues that judges should demand explanations for these algorithmic outcomes. One way to address the ‚Äúblack box‚Äù problem is to design systems that explain how the algorithms reach their conclusions or predictions. If and as judges demand these explanations, they will play a seminal role in shaping the nature and form of ‚Äúexplainable {AI}‚Äù ({xAI}). Using the tools of the common law, courts can develop what {xAI} should mean in different legal contexts. There are advantages to having courts to play this role: Judicial reasoning that builds from the bottom up, using case-by-case consideration of the facts to produce nuanced decisions, is a pragmatic way to develop rules for {xAI}. Further, courts are likely to stimulate the production of different forms of {xAI} that are responsive to distinct legal settings and audiences. More generally, we should favor the greater involvement of public actors in shaping {xAI}, which to date has largely been left in private hands.]},
	pages = {1829--1850},
	number = {7},
	journaltitle = {Columbia Law Review},
	author = {Deeks, Ashley},
	urldate = {2023-05-11},
	date = {2019},
	note = {Publisher: Columbia Law Review Association, Inc.},
}

@article{rueda_just_2022,
	title = {‚ÄúJust‚Äù accuracy? Procedural fairness demands explainability in {AI}-based medical resource allocations},
	issn = {1435-5655},
	url = {https://doi.org/10.1007/s00146-022-01614-9},
	doi = {10.1007/s00146-022-01614-9},
	abstract = {The increasing application of artificial intelligence ({AI}) to healthcare raises both hope and ethical concerns. Some advanced machine learning methods provide accurate clinical predictions at the expense of a significant lack of explainability. Alex John London has defended that accuracy is a more important value than explainability in {AI} medicine. In this article, we locate the trade-off between accurate performance and explainable algorithms in the context of distributive justice. We acknowledge that accuracy is cardinal from outcome-oriented justice because it helps to maximize patients‚Äô benefits and optimizes limited resources. However, we claim that the opaqueness of the algorithmic black box and its absence of explainability threatens core commitments of procedural fairness such as accountability, avoidance of bias, and transparency. To illustrate this, we discuss liver transplantation as a case of critical medical resources in which the lack of explainability in {AI}-based allocation algorithms is procedurally unfair. Finally, we provide a number of ethical recommendations for when considering the use of unexplainable algorithms in the distribution of health-related resources.},
	journaltitle = {{AI} \& {SOCIETY}},
	shortjournal = {{AI} \& {SOCIETY}},
	author = {Rueda, Jon and Rodr√≠guez, Janet Delgado and Jounou, Iris Parra and Hortal-Carmona, Joaqu√≠n and Aus√≠n, Txetxu and Rodr√≠guez-Arias, David},
	date = {2022-12-21},
}

@inproceedings{weber_quantifying_2021,
	location = {Cham},
	title = {Quantifying the Demand for¬†Explainability},
	isbn = {978-3-030-85616-8},
	doi = {10.1007/978-3-030-85616-8_38},
	series = {Lecture Notes in Computer Science},
	abstract = {Software that uses Artificial Intelligence technology like Machine Learning is becoming ubiquitous with even more applications ahead. Yet, the very nature of these systems has made it very hard to understand how they operate, creating a demand for explanations. While many approaches have been and are being developed, it remains unclear how strong this demand is for different domains, application types, and user groups. To assess this, we introduce a novel survey scale to quantify the demand for explainability. We also apply this scale to an exemplary set of applications, novel and traditional, in surveys with 212 participants, showing that interest in explainability is high in general for intelligent systems but also traditional software. While this validates the heightened interest in explainability, it also reveals further questions, e.g. where we can find synergies or how intelligent systems require different explanations compare to traditional but equally complex software.},
	pages = {652--661},
	booktitle = {Human-Computer Interaction ‚Äì {INTERACT} 2021},
	publisher = {Springer International Publishing},
	author = {Weber, Thomas and Hu√ümann, Heinrich and Eiband, Malin},
	editor = {Ardito, Carmelo and Lanzilotti, Rosa and Malizia, Alessio and Petrie, Helen and Piccinno, Antonio and Desolda, Giuseppe and Inkpen, Kori},
	date = {2021},
	langid = {english},
	keywords = {Explainable {AI}, Survey, Target group, Use case, {XAI}},
}

@online{noauthor_web_nodate,
	title = {Web of Science graphic},
	url = {https://www-webofscience-com.kuleuven.e-bronnen.be/wos/woscc/analyze-results/f407fdc7-f61f-44cf-aeac-4a2a1b1ae0e1-89473aa4},
	urldate = {2023-05-11},
}

@online{yingtong_graph-based_2023,
	title = {Graph-based Fraud Detection Papers and Resources},
	url = {https://github.com/safe-graph/graph-fraud-detection-papers},
	abstract = {A curated list of fraud detection papers using graph information or graph neural networks},
	author = {Yingtong, Dou},
	urldate = {2023-05-10},
	date = {2023-05-09},
	note = {original-date: 2019-11-21T05:39:23Z},
	keywords = {academic-publications, awsome-list, data-mining, data-science, deep-learning, fraud-detection, graph-algorithms, graph-convolutional-networks, graph-neural-networks, machine-learning, papers, security, spam-detection},
}

@online{bellei_elliptic_2019,
	title = {The Elliptic Data Set: opening up machine learning on the blockchain},
	url = {https://medium.com/elliptic/the-elliptic-data-set-opening-up-machine-learning-on-the-blockchain-e0a343d99a14},
	shorttitle = {The Elliptic Data Set},
	abstract = {Elliptic has recently released the Elliptic Data Set, a graph of 200,000 partially labeled bitcoin transactions. Here we give some more‚Ä¶},
	titleaddon = {Elliptic},
	author = {Bellei, Claudio},
	urldate = {2023-05-11},
	date = {2019-08-06},
	langid = {english},
}

@article{xu_spatio-temporal_2019,
	title = {Spatio-temporal attentive {RNN} for node classification in temporal attributed graphs: 28th International Joint Conference on Artificial Intelligence, {IJCAI} 2019},
	url = {http://www.scopus.com/inward/record.url?scp=85074905643&partnerID=8YFLogxK},
	doi = {10.24963/ijcai.2019/548},
	series = {{IJCAI} International Joint Conference on Artificial Intelligence},
	shorttitle = {Spatio-temporal attentive {RNN} for node classification in temporal attributed graphs},
	abstract = {Node classification in graph-structured data aims to classify the nodes where labels are only available for a subset of nodes. This problem has attracted considerable research efforts in recent years. In real-world applications, both graph topology and node attributes evolve over time. Existing techniques, however, mainly focus on static graphs and lack the capability to simultaneously learn both temporal and spatial/structural features. Node classification in temporal attributed graphs is challenging for two major aspects. First, effectively modeling the spatio-temporal contextual information is hard. Second, as temporal and spatial dimensions are entangled, to learn the feature representation of one target node, it's desirable and challenging to differentiate the relative importance of different factors, such as different neighbors and time periods. In this paper, we propose {STAR}, a spatio-temporal attentive recurrent network model, to deal with the above challenges. {STAR} extracts the vector representation of neighborhood by sampling and aggregating local neighbor nodes. It further feeds both the neighborhood representation and node attributes into a gated recurrent unit network to jointly learn the spatio-temporal contextual information. On top of that, we take advantage of the dual attention mechanism to perform a thorough analysis on the model interpretability. Extensive experiments on real datasets demonstrate the effectiveness of the {STAR} model.},
	pages = {3947--3953},
	journaltitle = {Proceedings of the 28th International Joint Conference on Artificial Intelligence, {IJCAI} 2019},
	author = {Xu, Dongkuan and Cheng, Wei and Luo, Dongsheng and Liu, Xiao and Zhang, Xiang},
	editor = {Kraus, Sarit},
	urldate = {2023-05-11},
	date = {2019},
	note = {Publisher: International Joint Conferences on Artificial Intelligence},
}

@misc{seo_structured_2016,
	title = {Structured Sequence Modeling with Graph Convolutional Recurrent Networks},
	url = {http://arxiv.org/abs/1612.07659},
	doi = {10.48550/arXiv.1612.07659},
	abstract = {This paper introduces Graph Convolutional Recurrent Network ({GCRN}), a deep learning model able to predict structured sequences of data. Precisely, {GCRN} is a generalization of classical recurrent neural networks ({RNN}) to data structured by an arbitrary graph. Such structured sequences can represent series of frames in videos, spatio-temporal measurements on a network of sensors, or random walks on a vocabulary graph for natural language modeling. The proposed model combines convolutional neural networks ({CNN}) on graphs to identify spatial structures and {RNN} to find dynamic patterns. We study two possible architectures of {GCRN}, and apply the models to two practical problems: predicting moving {MNIST} data, and modeling natural language with the Penn Treebank dataset. Experiments show that exploiting simultaneously graph spatial and dynamic information about data can improve both precision and learning speed.},
	number = {{arXiv}:1612.07659},
	publisher = {{arXiv}},
	author = {Seo, Youngjoo and Defferrard, Micha√´l and Vandergheynst, Pierre and Bresson, Xavier},
	urldate = {2023-05-11},
	date = {2016-12-22},
	eprinttype = {arxiv},
	eprint = {1612.07659 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@misc{velickovic_graph_2018,
	title = {Graph Attention Networks},
	url = {http://arxiv.org/abs/1710.10903},
	doi = {10.48550/arXiv.1710.10903},
	abstract = {We present graph attention networks ({GATs}), novel neural network architectures that operate on graph-structured data, leveraging masked self-attentional layers to address the shortcomings of prior methods based on graph convolutions or their approximations. By stacking layers in which nodes are able to attend over their neighborhoods' features, we enable (implicitly) specifying different weights to different nodes in a neighborhood, without requiring any kind of costly matrix operation (such as inversion) or depending on knowing the graph structure upfront. In this way, we address several key challenges of spectral-based graph neural networks simultaneously, and make our model readily applicable to inductive as well as transductive problems. Our {GAT} models have achieved or matched state-of-the-art results across four established transductive and inductive graph benchmarks: the Cora, Citeseer and Pubmed citation network datasets, as well as a protein-protein interaction dataset (wherein test graphs remain unseen during training).},
	number = {{arXiv}:1710.10903},
	publisher = {{arXiv}},
	author = {Veliƒçkoviƒá, Petar and Cucurull, Guillem and Casanova, Arantxa and Romero, Adriana and Li√≤, Pietro and Bengio, Yoshua},
	urldate = {2023-05-11},
	date = {2018-02-04},
	eprinttype = {arxiv},
	eprint = {1710.10903 [cs, stat]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Computer Science - Social and Information Networks, Statistics - Machine Learning},
}

@misc{agarwal_explainable_2022,
	title = {An Explainable {AI} Library for Benchmarking Graph Explainers},
	url = {https://graph-learning-benchmarks.github.io/assets/papers/glb2022/An_Explainable_AI_Library_for_Benchmarking_Graph_Explainers.pdf},
	abstract = {With Graph Neural Network ({GNN}) explainability methods increasingly used to understand {GNN} predictions in critical real-world applications, it is essential to reliably evaluate the correctness of generated explanations. However, assessing the quality of {GNN} explanations is challenging as existing evaluation strategies depend on specific datasets with no or unreliable ground-truth explanations and {GNN} models. Here, we introduce G-{XAI} Bench, an open-source graph explainability library providing a systematic framework in {PyTorch} and {PyTorch} Geometric to compare and evaluate the reliability of {GNN} explanations. G-{XAI} Bench provides comprehensive programmatic functionality in the form of data processing functions, {GNN} model implementations, collections of synthetic and real-world graph datasets, {GNN} explainers, and performance metrics to benchmark any {GNN} explainability method. We introduced G-{XAI} Bench to support the development of novel methods with a strong bent towards developing the foundations of which {GNN} explainers are most suitable for specific applications and why.},
	publisher = {Workshop on Graph Learning Benchmarks  ({GLB} 2022)},
	author = {Agarwal, Chirag and Queen, Owen and Lakkaraju, Himabindu and Zitnik, Marinka},
	date = {2022},
}

@article{ma_comprehensive_2021,
	title = {A Comprehensive Survey on Graph Anomaly Detection with Deep Learning},
	issn = {1558-2191},
	doi = {10.1109/TKDE.2021.3118815},
	abstract = {Over the last forty years, researches on anomalies have received intensified interests and the burst of information has attracted more attention on anomalies because of their significance in a wide range of disciplines. Anomaly detection, which aims to identify these rare observations, is among the most vital tasks and has shown its power in preventing detrimental events, such as financial fraud, network intrusion, and social spam, from happening. The detection task is typically solved by detecting outlying data in the features space and inherently overlooks the structural information. Graphs have been prevalently used to preserve structural information, and this raises the graph anomaly detection problem - identifying anomalous graph objects (nodes, edges, sub-graphs, and graphs). However, conventional anomaly detection techniques cannot well solve this problem because of the complexity of graph data. For the aptitudes of deep learning in breaking these limitations, graph anomaly detection with deep learning has received intensified studies recently. In this survey, we aim to provide a systematic and comprehensive review of the contemporary deep learning techniques for graph anomaly detection. We also highlight twelve extensive future research directions according to our survey results covering emerging problems introduced by graph data, anomaly detection and real applications.},
	pages = {1--1},
	journaltitle = {{IEEE} Transactions on Knowledge and Data Engineering},
	author = {Ma, Xiaoxiao and Wu, Jia and Xue, Shan and Yang, Jian and Zhou, Chuan and Sheng, Quan Z. and Xiong, Hui and Akoglu, Leman},
	date = {2021},
	note = {Conference Name: {IEEE} Transactions on Knowledge and Data Engineering},
	keywords = {Anomaly Detection, Anomaly detection, Deep Learning, Deep learning, Feature extraction, Graph Anomaly Detection, Graph Mining, Graph Neural Networks, Image edge detection, Object recognition, Social networking (online), Training},
}

@article{kim_graph_2022,
	title = {Graph Anomaly Detection With Graph Neural Networks: Current Status and Challenges},
	volume = {10},
	issn = {2169-3536},
	doi = {10.1109/ACCESS.2022.3211306},
	shorttitle = {Graph Anomaly Detection With Graph Neural Networks},
	abstract = {Graphs are used widely to model complex systems, and detecting anomalies in a graph is an important task in the analysis of complex systems. Graph anomalies are patterns in a graph that do not conform to normal patterns expected of the attributes and/or structures of the graph. In recent years, graph neural networks ({GNNs}) have been studied extensively and have successfully performed difficult machine learning tasks in node classification, link prediction, and graph classification thanks to the highly expressive capability via message passing in effectively learning graph representations. To solve the graph anomaly detection problem, {GNN}-based methods leverage information about the graph attributes (or features) and/or structures to learn to score anomalies appropriately. In this survey, we review the recent advances made in detecting graph anomalies using {GNN} models. Specifically, we summarize {GNN}-based methods according to the graph type (i.e., static and dynamic), the anomaly type (i.e., node, edge, subgraph, and whole graph), and the network architecture (e.g., graph autoencoder, graph convolutional network). To the best of our knowledge, this survey is the first comprehensive review of graph anomaly detection methods based on {GNNs}.},
	pages = {111820--111829},
	journaltitle = {{IEEE} Access},
	author = {Kim, Hwan and Lee, Byung Suk and Shin, Won-Yong and Lim, Sungsu},
	date = {2022},
	note = {Conference Name: {IEEE} Access},
	keywords = {Anomaly detection, Decoding, Deep learning, Dynamic graph, Feature extraction, Graph neural networks, Image edge detection, Message passing, graph anomaly detection, graph neural network, node anomaly, static graph},
}

@misc{fan_gcn-se_2021,
	title = {{GCN}-{SE}: Attention as Explainability for Node Classification in Dynamic Graphs},
	url = {http://arxiv.org/abs/2110.05598},
	doi = {10.48550/arXiv.2110.05598},
	shorttitle = {{GCN}-{SE}},
	abstract = {Graph Convolutional Networks ({GCNs}) are a popular method from graph representation learning that have proved effective for tasks like node classification tasks. Although typical {GCN} models focus on classifying nodes within a static graph, several recent variants propose node classification in dynamic graphs whose topologies and node attributes change over time, e.g., social networks with dynamic relationships, or literature citation networks with changing co-authorships. These works, however, do not fully address the challenge of flexibly assigning different importance to snapshots of the graph at different times, which depending on the graph dynamics may have more or less predictive power on the labels. We address this challenge by proposing a new method, {GCN}-{SE}, that attaches a set of learnable attention weights to graph snapshots at different times, inspired by Squeeze and Excitation Net ({SE}-Net). We show that {GCN}-{SE} outperforms previously proposed node classification methods on a variety of graph datasets. To verify the effectiveness of the attention weight in determining the importance of different graph snapshots, we adapt perturbation-based methods from the field of explainable machine learning to graphical settings and evaluate the correlation between the attention weights learned by {GCN}-{SE} and the importance of different snapshots over time. These experiments demonstrate that {GCN}-{SE} can in fact identify different snapshots' predictive power for dynamic node classification.},
	number = {{arXiv}:2110.05598},
	publisher = {{arXiv}},
	author = {Fan, Yucai and Yao, Yuhang and Joe-Wong, Carlee},
	urldate = {2023-05-09},
	date = {2021-10-11},
	eprinttype = {arxiv},
	eprint = {2110.05598 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Social and Information Networks},
}

@book{yang_fraudmemory_2019,
	title = {{FraudMemory}: Explainable Memory-Enhanced Sequential Neural Networks for Financial Fraud Detection},
	isbn = {978-0-9981331-2-6},
	url = {http://hdl.handle.net/10125/59542},
	shorttitle = {{FraudMemory}},
	abstract = {The rapid development of electronic financial services brings significant convenience to our daily life. However, it also offers criminals the opportunity to exploit financial systems to do fraudulent transactions. Previous studies on fraud detection only deal with single type transactions and cannot adapt well to evolving environment in reality. In addition, their black box models pay less attention on the interpretability of fraud detection results. Here we propose a novel fraud detection algorithm called {FraudMemory}. It adopts state-of-art feature representation methods to better depict users and logs with multiple types in financial systems. Our model innovatively uses sequential model to capture the sequential patterns of each transaction and leverages memory networks to improve both the performance and interpretability. Also, with the incorporation of memory components, {FraudMemory} possesses high adaptability to the existence of concept drift. The empirical study proves that our model is a potential tool for financial fraud detection.},
	author = {Yang, Kunlin and Xu, Wei},
	urldate = {2023-05-09},
	date = {2019-01-08},
}

@misc{limeros_towards_2022,
	title = {Towards Explainable Motion Prediction using Heterogeneous Graph Representations},
	url = {http://arxiv.org/abs/2212.03806},
	doi = {10.48550/arXiv.2212.03806},
	abstract = {Motion prediction systems aim to capture the future behavior of traffic scenarios enabling autonomous vehicles to perform safe and efficient planning. The evolution of these scenarios is highly uncertain and depends on the interactions of agents with static and dynamic objects in the scene. {GNN}-based approaches have recently gained attention as they are well suited to naturally model these interactions. However, one of the main challenges that remains unexplored is how to address the complexity and opacity of these models in order to deal with the transparency requirements for autonomous driving systems, which includes aspects such as interpretability and explainability. In this work, we aim to improve the explainability of motion prediction systems by using different approaches. First, we propose a new Explainable Heterogeneous Graph-based Policy ({XHGP}) model based on an heterograph representation of the traffic scene and lane-graph traversals, which learns interaction behaviors using object-level and type-level attention. This learned attention provides information about the most important agents and interactions in the scene. Second, we explore this same idea with the explanations provided by {GNNExplainer}. Third, we apply counterfactual reasoning to provide explanations of selected individual scenarios by exploring the sensitivity of the trained model to changes made to the input data, i.e., masking some elements of the scene, modifying trajectories, and adding or removing dynamic agents. The explainability analysis provided in this paper is a first step towards more transparent and reliable motion prediction systems, important from the perspective of the user, developers and regulatory agencies. The code to reproduce this work is publicly available at https://github.com/sancarlim/Explainable-{MP}/tree/v1.1.},
	number = {{arXiv}:2212.03806},
	publisher = {{arXiv}},
	author = {Limeros, Sandra Carrasco and Majchrowska, Sylwia and Johnander, Joakim and Petersson, Christoffer and Llorca, David Fern√°ndez},
	urldate = {2023-05-09},
	date = {2022-12-07},
	eprinttype = {arxiv},
	eprint = {2212.03806 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Robotics},
}

@misc{xie_explaining_2022,
	title = {Explaining Dynamic Graph Neural Networks via Relevance Back-propagation},
	url = {http://arxiv.org/abs/2207.11175},
	doi = {10.48550/arXiv.2207.11175},
	abstract = {Graph Neural Networks ({GNNs}) have shown remarkable effectiveness in capturing abundant information in graph-structured data. However, the black-box nature of {GNNs} hinders users from understanding and trusting the models, thus leading to difficulties in their applications. While recent years witness the prosperity of the studies on explaining {GNNs}, most of them focus on static graphs, leaving the explanation of dynamic {GNNs} nearly unexplored. It is challenging to explain dynamic {GNNs}, due to their unique characteristic of time-varying graph structures. Directly using existing models designed for static graphs on dynamic graphs is not feasible because they ignore temporal dependencies among the snapshots. In this work, we propose {DGExplainer} to provide reliable explanation on dynamic {GNNs}. {DGExplainer} redistributes the output activation score of a dynamic {GNN} to the relevances of the neurons of its previous layer, which iterates until the relevance scores of the input neuron are obtained. We conduct quantitative and qualitative experiments on real-world datasets to demonstrate the effectiveness of the proposed framework for identifying important nodes for link prediction and node regression for dynamic {GNNs}.},
	number = {{arXiv}:2207.11175},
	publisher = {{arXiv}},
	author = {Xie, Jiaxuan and Liu, Yezi and Shen, Yanning},
	urldate = {2023-05-09},
	date = {2022-07-22},
	eprinttype = {arxiv},
	eprint = {2207.11175 [cs]},
	keywords = {Computer Science - Machine Learning},
}

@misc{he_explainer_2022,
	title = {An Explainer for Temporal Graph Neural Networks},
	url = {http://arxiv.org/abs/2209.00807},
	doi = {10.48550/arXiv.2209.00807},
	abstract = {Temporal graph neural networks ({TGNNs}) have been widely used for modeling time-evolving graph-related tasks due to their ability to capture both graph topology dependency and non-linear temporal dynamic. The explanation of {TGNNs} is of vital importance for a transparent and trustworthy model. However, the complex topology structure and temporal dependency make explaining {TGNN} models very challenging. In this paper, we propose a novel explainer framework for {TGNN} models. Given a time series on a graph to be explained, the framework can identify dominant explanations in the form of a probabilistic graphical model in a time period. Case studies on the transportation domain demonstrate that the proposed approach can discover dynamic dependency structures in a road network for a time period.},
	number = {{arXiv}:2209.00807},
	publisher = {{arXiv}},
	author = {He, Wenchong and Vu, Minh N. and Jiang, Zhe and Thai, My T.},
	urldate = {2023-05-09},
	date = {2022-09-02},
	eprinttype = {arxiv},
	eprint = {2209.00807 [cs]},
	keywords = {Computer Science - Machine Learning},
}

@article{ye_explainable_2023,
	title = {Explainable {fMRI}‚Äêbased brain decoding via spatial temporal‚Äêpyramid graph convolutional network},
	volume = {44},
	issn = {1065-9471},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10089104/},
	doi = {10.1002/hbm.26255},
	abstract = {Brain decoding, aiming to identify the brain states using neural activity, is important for cognitive neuroscience and neural engineering. However, existing machine learning methods for {fMRI}‚Äêbased brain decoding either suffer from low classification performance or poor explainability. Here, we address this issue by proposing a biologically inspired architecture, Spatial Temporal‚Äêpyramid Graph Convolutional Network ({STpGCN}), to capture the spatial‚Äìtemporal graph representation of functional brain activities. By designing multi‚Äêscale spatial‚Äìtemporal pathways and bottom‚Äêup pathways that mimic the information process and temporal integration in the brain, {STpGCN} is capable of explicitly utilizing the multi‚Äêscale temporal dependency of brain activities via graph, thereby achieving high brain decoding performance. Additionally, we propose a sensitivity analysis method called {BrainNetX} to better explain the decoding results by automatically annotating task‚Äêrelated brain regions from the brain‚Äênetwork standpoint. We conduct extensive experiments on {fMRI} data under 23 cognitive tasks from Human Connectome Project ({HCP}) S1200. The results show that {STpGCN} significantly improves brain‚Äêdecoding performance compared to competing baseline models; {BrainNetX} successfully annotates task‚Äêrelevant brain regions. Post hoc analysis based on these regions further validates that the hierarchical structure in {STpGCN} significantly contributes to the explainability, robustness and generalization of the model. Our methods not only provide insights into information representation in the brain under multiple cognitive tasks but also indicate a bright future for {fMRI}‚Äêbased brain decoding., This work provides a biologically inspired graph deep learning‚Äêbased neural decoding method ({STpGCN}) and an model‚Äêagnostic explainable tool ({BrainNetX}). These two methods opens a new window for the brain decoding using graph neural networks with spatial and multiple‚Äêscale temporal dependencies. Besides the brain decoding, the proposed approaches hold promise for broad applications on neuroimages, such as brain disease detection.},
	pages = {2921--2935},
	number = {7},
	journaltitle = {Human Brain Mapping},
	shortjournal = {Hum Brain Mapp},
	author = {Ye, Ziyuan and Qu, Youzhi and Liang, Zhichao and Wang, Mo and Liu, Quanying},
	urldate = {2023-05-09},
	date = {2023-02-28},
	pmid = {36852610},
	pmcid = {PMC10089104},
}

@article{jiang_two-stage_2022,
	title = {Two-stage anomaly detection algorithm via dynamic community evolution in temporal graph},
	volume = {52},
	issn = {0924-669X, 1573-7497},
	url = {https://link.springer.com/10.1007/s10489-021-03109-4},
	doi = {10.1007/s10489-021-03109-4},
	abstract = {Detecting anomalies from a massive amount of user behavioral data is often liken to finding a needle in a haystack. While tremendous efforts have been devoted to anomaly detection from temporal graphs, existing studies rarely consider community evolution and evolutionary paths simultaneously, and analyze those characteristics for the purpose of anomaly detection. Therefore, we propose a two-stage anomaly detection ({TSAD}) framework to detect anomalies. In this study, we suggest detecting the community evolution events from a sequence of snapshot graphs by constructing an evolution bipartite graph and designing community similarity scores. We then propose a novel anomaly detection method combining community evolution-based anomaly detection and evolutionary path-based anomaly detection. An anomalous score is designed to detect anomalous community evolution events by extracting the characteristics of evolution communities in the community evolution-based anomaly detection method. Moreover, to reduce the false alarm rate, we propose evolutionary path-based anomaly detection to further detect the abnormality of the identified normal evolutionary paths by extracting the characteristics of the identified anomalous evolutionary paths based on community evolution-based anomaly detection. We conduct extensive experiments on real-world datasets and demonstrate that {TSAD} consistently outperforms competitive baseline methods in anomaly detection.},
	pages = {12222--12240},
	number = {11},
	journaltitle = {Applied Intelligence},
	shortjournal = {Appl Intell},
	author = {Jiang, Yan and Liu, Guannan},
	urldate = {2023-05-09},
	date = {2022-09},
	langid = {english},
}

@misc{lundberg_unified_2017,
	title = {A Unified Approach to Interpreting Model Predictions},
	url = {http://arxiv.org/abs/1705.07874},
	doi = {10.48550/arXiv.1705.07874},
	abstract = {Understanding why a model makes a certain prediction can be as crucial as the prediction's accuracy in many applications. However, the highest accuracy for large modern datasets is often achieved by complex models that even experts struggle to interpret, such as ensemble or deep learning models, creating a tension between accuracy and interpretability. In response, various methods have recently been proposed to help users interpret the predictions of complex models, but it is often unclear how these methods are related and when one method is preferable over another. To address this problem, we present a unified framework for interpreting predictions, {SHAP} ({SHapley} Additive {exPlanations}). {SHAP} assigns each feature an importance value for a particular prediction. Its novel components include: (1) the identification of a new class of additive feature importance measures, and (2) theoretical results showing there is a unique solution in this class with a set of desirable properties. The new class unifies six existing methods, notable because several recent methods in the class lack the proposed desirable properties. Based on insights from this unification, we present new methods that show improved computational performance and/or better consistency with human intuition than previous approaches.},
	number = {{arXiv}:1705.07874},
	publisher = {{arXiv}},
	author = {Lundberg, Scott and Lee, Su-In},
	urldate = {2023-05-09},
	date = {2017-11-24},
	eprinttype = {arxiv},
	eprint = {1705.07874 [cs, stat]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{yuan_explainability_2023,
	title = {Explainability in Graph Neural Networks: A Taxonomic Survey},
	volume = {45},
	issn = {1939-3539},
	doi = {10.1109/TPAMI.2022.3204236},
	shorttitle = {Explainability in Graph Neural Networks},
	abstract = {Deep learning methods are achieving ever-increasing performance on many artificial intelligence tasks. A major limitation of deep models is that they are not amenable to interpretability. This limitation can be circumvented by developing post hoc techniques to explain predictions, giving rise to the area of explainability. Recently, explainability of deep models on images and texts has achieved significant progress. In the area of graph data, graph neural networks ({GNNs}) and their explainability are experiencing rapid developments. However, there is neither a unified treatment of {GNN} explainability methods, nor a standard benchmark and testbed for evaluations. In this survey, we provide a unified and taxonomic view of current {GNN} explainability methods. Our unified and taxonomic treatments of this subject shed lights on the commonalities and differences of existing methods and set the stage for further methodological developments. To facilitate evaluations, we provide a testbed for {GNN} explainability, including datasets, common algorithms and evaluation metrics. Furthermore, we conduct comprehensive experiments to compare and analyze the performance of many techniques. Altogether, this work provides a unified methodological treatment of {GNN} explainability and a standardized testbed for evaluations.},
	pages = {5782--5799},
	number = {5},
	journaltitle = {{IEEE} Transactions on Pattern Analysis and Machine Intelligence},
	author = {Yuan, Hao and Yu, Haiyang and Gui, Shurui and Ji, Shuiwang},
	date = {2023-05},
	note = {Conference Name: {IEEE} Transactions on Pattern Analysis and Machine Intelligence},
	keywords = {Biological system modeling, Data models, Graph analysis, Graph neural networks, Predictive models, Systematics, Task analysis, Taxonomy, evaluation, explainability, graph neural networks, interpretability, survey, taxonomy},
}

@article{li_dynamic_2022,
	title = {Dynamic Graph-Based Anomaly Detection in the Electrical Grid},
	volume = {37},
	issn = {1558-0679},
	doi = {10.1109/TPWRS.2021.3132852},
	abstract = {Given sensor readings over time from a power grid, how can we accurately detect when an anomaly occurs? A key part of achieving this goal is to use the network of power grid sensors to quickly detect, in real-time, when any unusual events, whether natural faults or malicious, occur on the power grid. Existing bad-data detectors in the industry lack the sophistication to robustly detect broad types of anomalies, especially those due to emerging cyber-attacks, since they operate on a single measurement snapshot of the grid at a time. New {ML} methods are more widely applicable, but generally do not consider the impact of topology change on sensor measurements and thus cannot accommodate regular topology adjustments in historical data. Hence, we propose {DynWatch}, a domain knowledge based and topology-aware algorithm for anomaly detection using sensors placed on a dynamic grid. Our approach is accurate, outperforming existing approaches by 20\% or more (F-measure) in experiments; and fast, averaging less than 1.7 ms per time tick per sensor on a 60K+ branch case using a laptop computer, and scaling linearly with the size of the graph.},
	pages = {3408--3422},
	number = {5},
	journaltitle = {{IEEE} Transactions on Power Systems},
	author = {Li, Shimiao and Pandey, Amritanshu and Hooi, Bryan and Faloutsos, Christos and Pileggi, Larry},
	date = {2022-09},
	note = {Conference Name: {IEEE} Transactions on Power Systems},
	keywords = {Algorithms, Anomalies, Anomaly detection, Computer security, Electric power grids, Fault detection, {LODF}, Laptop computers, Network topology, Power grids, Power measurement, Power system dynamics, Sensors, Time series analysis, Topology, dynamic grid, graph distance, power system modeling},
}

@misc{acevedo-viloria_relational_2021,
	title = {Relational Graph Neural Networks for Fraud Detection in a Super-App environment},
	url = {http://arxiv.org/abs/2107.13673},
	doi = {10.48550/arXiv.2107.13673},
	abstract = {Large digital platforms create environments where different types of user interactions are captured, these relationships offer a novel source of information for fraud detection problems. In this paper we propose a framework of relational graph convolutional networks methods for fraudulent behaviour prevention in the financial services of a Super-App. To this end, we apply the framework on different heterogeneous graphs of users, devices, and credit cards; and finally use an interpretability algorithm for graph neural networks to determine the most important relations to the classification task of the users. Our results show that there is an added value when considering models that take advantage of the alternative data of the Super-App and the interactions found in their high connectivity, further proofing how they can leverage that into better decisions and fraud detection strategies.},
	number = {{arXiv}:2107.13673},
	publisher = {{arXiv}},
	author = {Acevedo-Viloria, Jaime D. and Roa, Luisa and Adeshina, Soji and Olazo, Cesar Charalla and Rodr√≠guez-Rey, Andr√©s and Ramos, Jose Alberto and Correa-Bahnsen, Alejandro},
	urldate = {2023-05-09},
	date = {2021-07-30},
	eprinttype = {arxiv},
	eprint = {2107.13673 [cs, q-fin]},
	keywords = {Computer Science - Machine Learning, Quantitative Finance - General Finance},
}

@inproceedings{qin_explainable_2022,
	location = {New York, {NY}, {USA}},
	title = {Explainable Graph-based Fraud Detection via Neural Meta-graph Search},
	isbn = {978-1-4503-9236-5},
	url = {https://dl.acm.org/doi/10.1145/3511808.3557598},
	doi = {10.1145/3511808.3557598},
	series = {{CIKM} '22},
	abstract = {Though graph neural networks ({GNNs})-based fraud detectors have received remarkable success in identifying fraudulent activities, few of them pay equal attention to models' performance and explainability. In this paper, we attempt to achieve high performance for graph-based fraud detection while considering model explainability. We propose {NGS} (Neural meta-Graph Search), in which the message passing process of a {GNN} is formalized as a meta-graph, and a differentiable neural architecture search is devised to determine the optimized message passing graph structure. We further enhance the model by aggregating multiple searched meta-graphs to make the final prediction. Experimental results on two real-world datasets demonstrate that {NGS} outperforms state-of-the-art baselines. In addition, the searched meta-graphs concisely describe the information used for prediction and produce reasonable explanations.},
	pages = {4414--4418},
	booktitle = {Proceedings of the 31st {ACM} International Conference on Information \& Knowledge Management},
	publisher = {Association for Computing Machinery},
	author = {Qin, Zidi and Liu, Yang and He, Qing and Ao, Xiang},
	urldate = {2023-05-09},
	date = {2022-10-17},
	keywords = {fraud detection, graph neural network, neural architecture search},
}

@misc{wu_dedgat_2023,
	title = {{DEDGAT}: Dual Embedding of Directed Graph Attention Networks for Detecting Financial Risk},
	url = {http://arxiv.org/abs/2303.03933},
	doi = {10.48550/arXiv.2303.03933},
	shorttitle = {{DEDGAT}},
	abstract = {Graph representation plays an important role in the field of financial risk control, where the relationship among users can be constructed in a graph manner. In practical scenarios, the relationships between nodes in risk control tasks are bidirectional, e.g., merchants having both revenue and expense behaviors. Graph neural networks designed for undirected graphs usually aggregate discriminative node or edge representations with an attention strategy, but cannot fully exploit the out-degree information when used for the tasks built on directed graph, which leads to the problem of a directional bias. To tackle this problem, we propose a Directed Graph {ATtention} network called {DGAT}, which explicitly takes out-degree into attention calculation. In addition to having directional requirements, the same node might have different representations of its input and output, and thus we further propose a dual embedding of {DGAT}, referred to as {DEDGAT}. Specifically, {DEDGAT} assigns in-degree and out-degree representations to each node and uses these two embeddings to calculate the attention weights of in-degree and out-degree nodes, respectively. Experiments performed on the benchmark datasets show that {DGAT} and {DEDGAT} obtain better classification performance compared to undirected {GAT}. Also,the visualization results demonstrate that our methods can fully use both in-degree and out-degree information.},
	number = {{arXiv}:2303.03933},
	publisher = {{arXiv}},
	author = {Wu, Jiafu and Yao, Mufeng and Wu, Dong and Chi, Mingmin and Wang, Baokun and Wu, Ruofan and Fu, Xin and Meng, Changhua and Wang, Weiqiang},
	urldate = {2023-05-09},
	date = {2023-03-06},
	eprinttype = {arxiv},
	eprint = {2303.03933 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Distributed, Parallel, and Cluster Computing, Computer Science - Machine Learning},
}

@article{rao_xfraud_2021,
	title = {{xFraud}: explainable fraud transaction detection},
	volume = {15},
	issn = {2150-8097},
	url = {https://dl.acm.org/doi/10.14778/3494124.3494128},
	doi = {10.14778/3494124.3494128},
	shorttitle = {{xFraud}},
	abstract = {At online retail platforms, it is crucial to actively detect the risks of transactions to improve customer experience and minimize financial loss. In this work, we propose {xFraud}, an explainable fraud transaction prediction framework which is mainly composed of a detector and an explainer. The {xFraud} detector can effectively and efficiently predict the legitimacy of incoming transactions. Specifically, it utilizes a heterogeneous graph neural network to learn expressive representations from the informative heterogeneously typed entities in the transaction logs. The explainer in {xFraud} can generate meaningful and human-understandable explanations from graphs to facilitate further processes in the business unit. In our experiments with {xFraud} on real transaction networks with up to 1.1 billion nodes and 3.7 billion edges, {xFraud} is able to outperform various baseline models in many evaluation metrics while remaining scalable in distributed settings. In addition, we show that {xFraud} explainer can generate reasonable explanations to significantly assist the business analysis via both quantitative and qualitative evaluations.},
	pages = {427--436},
	number = {3},
	journaltitle = {Proceedings of the {VLDB} Endowment},
	shortjournal = {Proc. {VLDB} Endow.},
	author = {Rao, Susie Xi and Zhang, Shuai and Han, Zhichao and Zhang, Zitao and Min, Wei and Chen, Zhiyao and Shan, Yinan and Zhao, Yang and Zhang, Ce},
	urldate = {2023-05-09},
	date = {2021-11-01},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Computer Science - Social and Information Networks, I.2.6},
}

@misc{li_explainability_2022,
	title = {Explainability in Graph Neural Networks: An Experimental Survey},
	url = {http://arxiv.org/abs/2203.09258},
	doi = {10.48550/arXiv.2203.09258},
	shorttitle = {Explainability in Graph Neural Networks},
	abstract = {Graph neural networks ({GNNs}) have been extensively developed for graph representation learning in various application domains. However, similar to all other neural networks models, {GNNs} suffer from the black-box problem as people cannot understand the mechanism underlying them. To solve this problem, several {GNN} explainability methods have been proposed to explain the decisions made by {GNNs}. In this survey, we give an overview of the state-of-the-art {GNN} explainability methods and how they are evaluated. Furthermore, we propose a new evaluation metric and conduct thorough experiments to compare {GNN} explainability methods on real world datasets. We also suggest future directions for {GNN} explainability.},
	number = {{arXiv}:2203.09258},
	publisher = {{arXiv}},
	author = {Li, Peibo and Yang, Yixing and Pagnucco, Maurice and Song, Yang},
	urldate = {2023-05-09},
	date = {2022-03-17},
	eprinttype = {arxiv},
	eprint = {2203.09258 [cs]},
	keywords = {A.1, Computer Science - Artificial Intelligence, Computer Science - Machine Learning, I.2.0},
}

@misc{dai_comprehensive_2022,
	title = {A Comprehensive Survey on Trustworthy Graph Neural Networks: Privacy, Robustness, Fairness, and Explainability},
	url = {http://arxiv.org/abs/2204.08570},
	doi = {10.48550/arXiv.2204.08570},
	shorttitle = {A Comprehensive Survey on Trustworthy Graph Neural Networks},
	abstract = {Graph Neural Networks ({GNNs}) have made rapid developments in the recent years. Due to their great ability in modeling graph-structured data, {GNNs} are vastly used in various applications, including high-stakes scenarios such as financial analysis, traffic predictions, and drug discovery. Despite their great potential in benefiting humans in the real world, recent study shows that {GNNs} can leak private information, are vulnerable to adversarial attacks, can inherit and magnify societal bias from training data and lack interpretability, which have risk of causing unintentional harm to the users and society. For example, existing works demonstrate that attackers can fool the {GNNs} to give the outcome they desire with unnoticeable perturbation on training graph. {GNNs} trained on social networks may embed the discrimination in their decision process, strengthening the undesirable societal bias. Consequently, trustworthy {GNNs} in various aspects are emerging to prevent the harm from {GNN} models and increase the users' trust in {GNNs}. In this paper, we give a comprehensive survey of {GNNs} in the computational aspects of privacy, robustness, fairness, and explainability. For each aspect, we give the taxonomy of the related methods and formulate the general frameworks for the multiple categories of trustworthy {GNNs}. We also discuss the future research directions of each aspect and connections between these aspects to help achieve trustworthiness.},
	number = {{arXiv}:2204.08570},
	publisher = {{arXiv}},
	author = {Dai, Enyan and Zhao, Tianxiang and Zhu, Huaisheng and Xu, Junjie and Guo, Zhimeng and Liu, Hui and Tang, Jiliang and Wang, Suhang},
	urldate = {2023-05-09},
	date = {2022-04-18},
	eprinttype = {arxiv},
	eprint = {2204.08570 [cs]},
	keywords = {Computer Science - Cryptography and Security, Computer Science - Machine Learning},
}

@misc{amara_graphframex_2022,
	title = {{GraphFramEx}: Towards Systematic Evaluation of Explainability Methods for Graph Neural Networks},
	url = {http://arxiv.org/abs/2206.09677},
	doi = {10.48550/arXiv.2206.09677},
	shorttitle = {{GraphFramEx}},
	abstract = {As one of the most popular machine learning models today, graph neural networks ({GNNs}) have attracted intense interest recently, and so does their explainability. Users are increasingly interested in a better understanding of {GNN} models and their outcomes. Unfortunately, today's evaluation frameworks for {GNN} explainability often rely on few inadequate synthetic datasets, leading to conclusions of limited scope due to a lack of complexity in the problem instances. As {GNN} models are deployed to more mission-critical applications, we are in dire need for a common evaluation protocol of explainability methods of {GNNs}. In this paper, we propose, to our best knowledge, the first systematic evaluation framework for {GNN} explainability, considering explainability on three different "user needs". We propose a unique metric that combines the fidelity measures and classifies explanations based on their quality of being sufficient or necessary. We scope ourselves to node classification tasks and compare the most representative techniques in the field of input-level explainability for {GNNs}. For the inadequate but widely used synthetic benchmarks, surprisingly shallow techniques such as personalized {PageRank} have the best performance for a minimum computation time. But when the graph structure is more complex and nodes have meaningful features, gradient-based methods are the best according to our evaluation criteria. However, none dominates the others on all evaluation dimensions and there is always a trade-off. We further apply our evaluation protocol in a case study for frauds explanation on {eBay} transaction graphs to reflect the production environment.},
	number = {{arXiv}:2206.09677},
	publisher = {{arXiv}},
	author = {Amara, Kenza and Ying, Rex and Zhang, Zitao and Han, Zhihao and Shan, Yinan and Brandes, Ulrik and Schemm, Sebastian and Zhang, Ce},
	urldate = {2023-05-09},
	date = {2022-10-11},
	eprinttype = {arxiv},
	eprint = {2206.09677 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
}

@misc{pareja_evolvegcn_2019,
	title = {{EvolveGCN}: Evolving Graph Convolutional Networks for Dynamic Graphs},
	url = {http://arxiv.org/abs/1902.10191},
	doi = {10.48550/arXiv.1902.10191},
	shorttitle = {{EvolveGCN}},
	abstract = {Graph representation learning resurges as a trending research subject owing to the widespread use of deep learning for Euclidean data, which inspire various creative designs of neural networks in the non-Euclidean domain, particularly graphs. With the success of these graph neural networks ({GNN}) in the static setting, we approach further practical scenarios where the graph dynamically evolves. Existing approaches typically resort to node embeddings and use a recurrent neural network ({RNN}, broadly speaking) to regulate the embeddings and learn the temporal dynamics. These methods require the knowledge of a node in the full time span (including both training and testing) and are less applicable to the frequent change of the node set. In some extreme scenarios, the node sets at different time steps may completely differ. To resolve this challenge, we propose {EvolveGCN}, which adapts the graph convolutional network ({GCN}) model along the temporal dimension without resorting to node embeddings. The proposed approach captures the dynamism of the graph sequence through using an {RNN} to evolve the {GCN} parameters. Two architectures are considered for the parameter evolution. We evaluate the proposed approach on tasks including link prediction, edge classification, and node classification. The experimental results indicate a generally higher performance of {EvolveGCN} compared with related approaches. The code is available at {\textbackslash}url\{https://github.com/{IBM}/{EvolveGCN}\}.},
	number = {{arXiv}:1902.10191},
	publisher = {{arXiv}},
	author = {Pareja, Aldo and Domeniconi, Giacomo and Chen, Jie and Ma, Tengfei and Suzumura, Toyotaro and Kanezashi, Hiroki and Kaler, Tim and Schardl, Tao B. and Leiserson, Charles E.},
	urldate = {2023-05-09},
	date = {2019-11-18},
	eprinttype = {arxiv},
	eprint = {1902.10191 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Computer Science - Social and Information Networks, Statistics - Machine Learning},
}

@inproceedings{rozemberczki_pytorch_2021,
	location = {New York, {NY}, {USA}},
	title = {{PyTorch} Geometric Temporal: Spatiotemporal Signal Processing with Neural Machine Learning Models},
	isbn = {978-1-4503-8446-9},
	url = {https://dl.acm.org/doi/10.1145/3459637.3482014},
	doi = {10.1145/3459637.3482014},
	series = {{CIKM} '21},
	shorttitle = {{PyTorch} Geometric Temporal},
	abstract = {We present {PyTorch} Geometric Temporal, a deep learning framework combining state-of-the-art machine learning algorithms for neural spatiotemporal signal processing. The main goal of the library is to make temporal geometric deep learning available for researchers and machine learning practitioners in a unified easy-to-use framework. {PyTorch} Geometric Temporal was created with foundations on existing libraries in the {PyTorch} eco-system, streamlined neural network layer definitions, temporal snapshot generators for batching, and integrated benchmark datasets. These features are illustrated with a tutorial-like case study. Experiments demonstrate the predictive performance of the models implemented in the library on real-world problems such as epidemiological forecasting, ride-hail demand prediction, and web traffic management. Our sensitivity analysis of runtime shows that the framework can potentially operate on web-scale datasets with rich temporal features and spatial structure.},
	pages = {4564--4573},
	booktitle = {Proceedings of the 30th {ACM} International Conference on Information \& Knowledge Management},
	publisher = {Association for Computing Machinery},
	author = {Rozemberczki, Benedek and Scherer, Paul and He, Yixuan and Panagopoulos, George and Riedel, Alexander and Astefanoaei, Maria and Kiss, Oliver and Beres, Ferenc and L√≥pez, Guzm√°n and Collignon, Nicolas and Sarkar, Rik},
	urldate = {2023-05-09},
	date = {2021-10-30},
	keywords = {deep learning, graph neural networks, machine learning, time series data},
}

@misc{rao_modelling_2022,
	title = {Modelling graph dynamics in fraud detection with "Attention"},
	url = {http://arxiv.org/abs/2204.10614},
	abstract = {At online retail platforms, detecting fraudulent accounts and transactions is crucial to improve customer experience, minimize loss, and avoid unauthorized transactions. Despite the variety of different models for deep learning on graphs, few approaches have been proposed for dealing with graphs that are both heterogeneous and dynamic. In this paper, we propose {DyHGN} (Dynamic Heterogeneous Graph Neural Network) and its variants to capture both temporal and heterogeneous information. We first construct dynamic heterogeneous graphs from registration and transaction data from {eBay}. Then, we build models with diachronic entity embedding and heterogeneous graph transformer. We also use model explainability techniques to understand the behaviors of {DyHGN}-* models. Our findings reveal that modelling graph dynamics with heterogeneous inputs need to be conducted with ‚Äúattention" depending on the data structure, distribution, and computation cost.},
	number = {{arXiv}:2204.10614},
	publisher = {{arXiv}},
	author = {Rao, Susie Xi and Lanfranchi, Cl√©mence and Zhang, Shuai and Han, Zhichao and Zhang, Zitao and Min, Wei and Cheng, Mo and Shan, Yinan and Zhao, Yang and Zhang, Ce},
	urldate = {2022-11-27},
	date = {2022-04-22},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {2204.10614 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Computer Science - Social and Information Networks},
}

@inproceedings{zheng_addgraph_2019,
	location = {Macao, China},
	title = {{AddGraph}: Anomaly Detection in Dynamic Graph Using Attention-based Temporal {GCN}},
	isbn = {978-0-9992411-4-1},
	url = {https://www.ijcai.org/proceedings/2019/614},
	doi = {10.24963/ijcai.2019/614},
	shorttitle = {{AddGraph}},
	abstract = {Anomaly detection in dynamic graphs becomes very critical in many different application scenarios, e.g., recommender systems, while it also raises huge challenges due to the high Ô¨Çexible nature of anomaly and lack of sufÔ¨Åcient labelled data. It is better to learn the anomaly patterns by considering all possible hints including the structural, content and temporal features, rather than utilizing heuristic rules over the partial features. In this paper, we propose {AddGraph}, a general end-to-end anomalous edge detection framework using an extended temporal {GCN} (Graph Convolutional Network) with an attention model, which can capture both long-term patterns and the short-term patterns in dynamic graphs. In order to cope with insufÔ¨Åcient explicit labelled data, we employ a selective negative sampling and margin loss in training of {AddGraph} in a semi-supervised fashion. We conduct extensive experiments on real-world datasets, and illustrate that {AddGraph} can outperform the state-of-the-art competitors in anomaly detection signiÔ¨Åcantly.},
	eventtitle = {Twenty-Eighth International Joint Conference on Artificial Intelligence \{{IJCAI}-19\}},
	pages = {4419--4425},
	booktitle = {Proceedings of the Twenty-Eighth International Joint Conference on Artificial Intelligence},
	publisher = {International Joint Conferences on Artificial Intelligence Organization},
	author = {Zheng, Li and Li, Zhenpeng and Li, Jian and Li, Zhao and Gao, Jun},
	urldate = {2022-11-30},
	date = {2019-08},
	langid = {english},
}

@misc{lv_are_2021,
	title = {Are we really making much progress? Revisiting, benchmarking, and refining heterogeneous graph neural networks},
	url = {http://arxiv.org/abs/2112.14936},
	shorttitle = {Are we really making much progress?},
	abstract = {Heterogeneous graph neural networks ({HGNNs}) have been blossoming in recent years, but the unique data processing and evaluation setups used by each work obstruct a full understanding of their advancements. In this work, we present a systematical reproduction of 12 recent {HGNNs} by using their official codes, datasets, settings, and hyperparameters, revealing surprising findings about the progress of {HGNNs}. We find that the simple homogeneous {GNNs}, e.g., {GCN} and {GAT}, are largely underestimated due to improper settings. {GAT} with proper inputs can generally match or outperform all existing {HGNNs} across various scenarios. To facilitate robust and reproducible {HGNN} research, we construct the Heterogeneous Graph Benchmark ({HGB})1, consisting of 11 diverse datasets with three tasks. {HGB} standardizes the process of heterogeneous graph data splits, feature processing, and performance evaluation. Finally, we introduce a simple but very strong baseline Simple-{HGN}‚Äîwhich significantly outperforms all previous models on {HGB}‚Äîto accelerate the advancement of {HGNNs} in the future.},
	number = {{arXiv}:2112.14936},
	publisher = {{arXiv}},
	author = {Lv, Qingsong and Ding, Ming and Liu, Qiang and Chen, Yuxiang and Feng, Wenzheng and He, Siming and Zhou, Chang and Jiang, Jianguo and Dong, Yuxiao and Tang, Jie},
	urldate = {2023-05-02},
	date = {2021-12-30},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {2112.14936 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Social and Information Networks},
}

@misc{cai_structural_2020,
	title = {Structural Temporal Graph Neural Networks for Anomaly Detection in Dynamic Graphs},
	url = {http://arxiv.org/abs/2005.07427},
	abstract = {Detecting anomalies in dynamic graphs is a vital task, with numerous practical applications in areas such as security, Ô¨Ånance, and social media. Previous network embedding based methods have been mostly focusing on learning good node representations, whereas largely ignoring the subgraph structural changes related to the target nodes in dynamic graphs. In this paper, we propose {StrGNN}, an end-to-end structural temporal Graph Neural Network model for detecting anomalous edges in dynamic graphs. In particular, we Ô¨Årst extract the hhop enclosing subgraph centered on the target edge and propose the node labeling function to identify the role of each node in the subgraph. Then, we leverage graph convolution operation and Sortpooling layer to extract the Ô¨Åxed-size feature from each snapshot/timestamp. Based on the extracted features, we utilize Gated recurrent units ({GRUs}) to capture the temporal information for anomaly detection. Extensive experiments on six benchmark datasets and a real enterprise security system demonstrate the effectiveness of {StrGNN}.},
	number = {{arXiv}:2005.07427},
	publisher = {{arXiv}},
	author = {Cai, Lei and Chen, Zhengzhang and Luo, Chen and Gui, Jiaping and Ni, Jingchao and Li, Ding and Chen, Haifeng},
	urldate = {2023-05-02},
	date = {2020-05-25},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {2005.07427 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Computer Science - Social and Information Networks, Statistics - Machine Learning},
}

@misc{zhang_trustworthy_2022,
	title = {Trustworthy Graph Neural Networks: Aspects, Methods and Trends},
	url = {http://arxiv.org/abs/2205.07424},
	shorttitle = {Trustworthy Graph Neural Networks},
	abstract = {Graph neural networks ({GNNs}) have emerged as a series of competent graph learning methods for diverse real-world scenarios, ranging from daily applications like recommendation systems and question answering to cutting-edge technologies such as drug discovery in life sciences and n-body simulation in astrophysics. However, task performance is not the only requirement for {GNNs}. Performance-oriented {GNNs} have exhibited potential adverse effects like vulnerability to adversarial attacks, unexplainable discrimination against disadvantaged groups, or excessive resource consumption in edge computing environments. To avoid these unintentional harms, it is necessary to build competent {GNNs} characterised by trustworthiness. To this end, we propose a comprehensive roadmap to build trustworthy {GNNs} from the view of the various computing technologies involved. In this survey, we introduce basic concepts and comprehensively summarise existing efforts for trustworthy {GNNs} from six aspects, including robustness, explainability, privacy, fairness, accountability, and environmental well-being. Additionally, we highlight the intricate cross-aspect relations between the above six aspects of trustworthy {GNNs}. Finally, we present a thorough overview of trending directions for facilitating the research and industrialisation of trustworthy {GNNs}.},
	number = {{arXiv}:2205.07424},
	publisher = {{arXiv}},
	author = {Zhang, He and Wu, Bang and Yuan, Xingliang and Pan, Shirui and Tong, Hanghang and Pei, Jian},
	urldate = {2023-05-02},
	date = {2022-05-15},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {2205.07424 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
}

@article{akoglu_graph_2015,
	title = {Graph based anomaly detection and description: a survey},
	volume = {29},
	issn = {1384-5810, 1573-756X},
	url = {http://link.springer.com/10.1007/s10618-014-0365-y},
	doi = {10.1007/s10618-014-0365-y},
	shorttitle = {Graph based anomaly detection and description},
	pages = {626--688},
	number = {3},
	journaltitle = {Data Mining and Knowledge Discovery},
	shortjournal = {Data Min Knowl Disc},
	author = {Akoglu, Leman and Tong, Hanghang and Koutra, Danai},
	urldate = {2022-11-27},
	date = {2015-05},
	langid = {english},
}
