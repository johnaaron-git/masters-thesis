The scope of this study encompassed a comprehensive overview of dynamic anomaly detection and explainability methods, noting their importance in fraud-specific applications. By addressing existing potential challenges and providing future directions for explainability development, it attempts to encourage future growth in this research space.

Reflecting on novel developments in this field allowed for the proposal of a holistic experimental method that covers essential considerations from data selection and pre-processing through to explainer validation. We make special emphasis on the potential of modified static explainers for temporal models. Our work ultimately aims to serve as both a guide towards practical experimental application, and a time-saving source of up-to-date information. It seeks to play at least a small part in paving the way for more interpretable, quantifiable machine learning decisions that can be applied across specialties.